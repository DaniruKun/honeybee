{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna.integration.lightgbm as optuna_lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math\n",
    "from operator import itemgetter\n",
    "import itertools\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "\n",
    "# https://gist.github.com/vbkaisetsu/d7c08e9c5aabe13686dd554ddfadf076\n",
    "def suffix_array(arr):\n",
    "    arr_size = len(arr)\n",
    "    arr_int = {v: k for k, v in enumerate(sorted(set(arr)))}\n",
    "    arr = [arr_int[x] for x in arr]\n",
    "    arr.append(-1)\n",
    "    suf = [[i, arr[i], arr[i + 1]] for i in range(arr_size)]\n",
    "    suf.sort(key=itemgetter(1, 2))\n",
    "    idx = [0] * arr_size\n",
    "    k = 2\n",
    "    while k < arr_size:\n",
    "        r = 0\n",
    "        prev_r = suf[0][1]\n",
    "        for i in range(arr_size):\n",
    "            if suf[i][1] != prev_r or suf[i - 1][2] != suf[i][2]:\n",
    "                r += 1\n",
    "            prev_r = suf[i][1]\n",
    "            suf[i][1] = r\n",
    "            idx[suf[i][0]] = i\n",
    "        for i in range(arr_size):\n",
    "            next_idx = suf[i][0] + k\n",
    "            suf[i][2] = suf[idx[next_idx]][1] if next_idx < arr_size else -1\n",
    "        suf.sort(key=itemgetter(1, 2))\n",
    "        k <<= 1\n",
    "    return [x[0] for x in suf]\n",
    "\n",
    "\n",
    "# https://gist.github.com/vbkaisetsu/d7c08e9c5aabe13686dd554ddfadf076\n",
    "def bwt_encode(data):\n",
    "    data_ref = suffix_array(data)\n",
    "    bwt_ref = (x - 1 for x in data_ref)\n",
    "    return ''.join([data[x] for x in bwt_ref])\n",
    "\n",
    "\n",
    "def balanced_bwt_rl_entropy(text):\n",
    "    rl_len = len([ch for ch, _ in itertools.groupby(bwt_encode(text))])\n",
    "    return math.exp(len(text) / rl_len)\n",
    "\n",
    "\n",
    "data_dir = '../data'\n",
    "train_data_path = join(data_dir, 'train.parquet')\n",
    "\n",
    "\n",
    "def loadData():\n",
    "    df = pd.read_parquet(train_data_path)\n",
    "    df.drop(columns=[\n",
    "        'id', 'authorName', 'authorPhoto', 'authorChannelId', 'timestampUsec',\n",
    "        'originChannelId', 'originVideoId', 'membership', 'purchase',\n",
    "        'rawMessage', 'message'\n",
    "    ],\n",
    "            inplace=True)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2814\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = loadData()\n",
    "\n",
    "grp = data.groupby('spam')\n",
    "grp = grp.apply(lambda x: x.sample(grp.size().min()))\n",
    "data = pd.DataFrame(grp).reset_index(drop=True)\n",
    "print(len(data))\n",
    "\n",
    "x = data.drop(columns='spam')\n",
    "y = data['spam']\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33)\n",
    "# print(x_train.head())\n",
    "# print(y_train.head())\n",
    "# validation_data = lgb.Dataset(x_test, label=y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'n_split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/trainer/train.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtscv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimeSeriesSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m param = {\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m'device_type'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'gpu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m'objective'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'binary'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/.venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'n_split'"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data = lgb.Dataset(x, label=y)\n",
    "tscv = TimeSeriesSplit(n_split=5)\n",
    "param = {\n",
    "    'device_type': 'gpu',\n",
    "    'objective': 'binary',\n",
    "    'boosting': 'gbdt',\n",
    "    # 'metric': 'kullback_leibler',\n",
    "    # 'metric': 'auc',\n",
    "    # 'is_unbalance': True,\n",
    "}\n",
    "\n",
    "bst = optuna_lgb.cv(param, train_data, folds=tscv)\n",
    "bst.save_model('model.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hat meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'save_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/trainer/train.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna_lgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtscv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'save_model'"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data = lgb.Dataset(x, label=y)\n",
    "tscv = TimeSeriesSplit()\n",
    "param = {\n",
    "    'device_type': 'gpu',\n",
    "    'objective': 'binary',\n",
    "    'boosting': 'gbdt',\n",
    "    # 'metric': 'kullback_leibler',\n",
    "    # 'metric': 'auc',\n",
    "    # 'is_unbalance': True,\n",
    "}\n",
    "\n",
    "bst = optuna_lgb.cv(param, train_data, folds=tscv)\n",
    "bst.save_model('model.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/trainer/train.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m }\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna_lgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/.venv/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, train_set, num_boost_round, folds, nfold, stratified, shuffle, metrics, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, fpreproc, verbose_eval, show_stdv, seed, callbacks, eval_train_metric, return_cvbooster)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m     cvfolds = _make_n_folds(train_set, folds=folds, nfold=nfold,\n\u001b[0m\u001b[1;32m    561\u001b[0m                             \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpreproc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfpreproc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                             \u001b[0mstratified\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratified\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/.venv/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36m_make_n_folds\u001b[0;34m(full_data, folds, nfold, params, seed, fpreproc, stratified, shuffle, eval_train_metric)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCVBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m         \u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0mvalid_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/.venv/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    330\u001b[0m                 .format(self.n_splits, n_samples))\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/.venv/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0mtrain_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mtest_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/.venv/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_test_masks\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m         \u001b[0mtest_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_folds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtest_folds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/.venv/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_make_test_folds\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0mallowed_target_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'binary'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'multiclass'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype_of_target_y\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_target_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    646\u001b[0m                 'Supported target types are: {}. Got {!r} instead.'.format(\n\u001b[1;32m    647\u001b[0m                     allowed_target_types, type_of_target_y))\n",
      "\u001b[0;31mValueError\u001b[0m: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead."
     ]
    }
   ],
   "source": [
    "\n",
    "train_data = lgb.Dataset(x, label=y)\n",
    "tscv = TimeSeriesSplit()\n",
    "param = {\n",
    "    'device_type': 'gpu',\n",
    "    'objective': 'binary',\n",
    "    'boosting': 'gbdt',\n",
    "    # 'metric': 'kullback_leibler',\n",
    "    # 'metric': 'auc',\n",
    "    # 'is_unbalance': True,\n",
    "}\n",
    "\n",
    "bst = optuna_lgb.cv(param, train_data)\n",
    "bst.save_model('model.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/trainer/train.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m }\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna_lgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/.venv/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, train_set, num_boost_round, folds, nfold, stratified, shuffle, metrics, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, fpreproc, verbose_eval, show_stdv, seed, callbacks, eval_train_metric, return_cvbooster)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m     cvfolds = _make_n_folds(train_set, folds=folds, nfold=nfold,\n\u001b[0m\u001b[1;32m    561\u001b[0m                             \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpreproc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfpreproc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                             \u001b[0mstratified\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratified\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/.venv/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36m_make_n_folds\u001b[0;34m(full_data, folds, nfold, params, seed, fpreproc, stratified, shuffle, eval_train_metric)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCVBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m         \u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0mvalid_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/.venv/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    330\u001b[0m                 .format(self.n_splits, n_samples))\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/.venv/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0mtrain_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mtest_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/.venv/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_test_masks\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m         \u001b[0mtest_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_folds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtest_folds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/.venv/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_make_test_folds\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0mallowed_target_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'binary'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'multiclass'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype_of_target_y\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_target_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    646\u001b[0m                 'Supported target types are: {}. Got {!r} instead.'.format(\n\u001b[1;32m    647\u001b[0m                     allowed_target_types, type_of_target_y))\n",
      "\u001b[0;31mValueError\u001b[0m: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead."
     ]
    }
   ],
   "source": [
    "\n",
    "train_data = lgb.Dataset(x, label=y)\n",
    "tscv = TimeSeriesSplit()\n",
    "param = {\n",
    "    'device_type': 'gpu',\n",
    "    'objective': 'binary',\n",
    "    'boosting': 'gbdt',\n",
    "    # 'metric': 'kullback_leibler',\n",
    "    # 'metric': 'auc',\n",
    "    # 'is_unbalance': True,\n",
    "}\n",
    "\n",
    "bst = optuna_lgb.cv(param, train_data)\n",
    "bst.save_model('model.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/trainer/train.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# 'is_unbalance': True,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m }\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/.venv/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, train_set, num_boost_round, folds, nfold, stratified, shuffle, metrics, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, fpreproc, verbose_eval, show_stdv, seed, callbacks, eval_train_metric, return_cvbooster)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m     cvfolds = _make_n_folds(train_set, folds=folds, nfold=nfold,\n\u001b[0m\u001b[1;32m    561\u001b[0m                             \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpreproc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfpreproc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                             \u001b[0mstratified\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratified\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/.venv/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36m_make_n_folds\u001b[0;34m(full_data, folds, nfold, params, seed, fpreproc, stratified, shuffle, eval_train_metric)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCVBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m         \u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0mvalid_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/.venv/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    330\u001b[0m                 .format(self.n_splits, n_samples))\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/.venv/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0mtrain_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mtest_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/.venv/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_test_masks\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m         \u001b[0mtest_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_folds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtest_folds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/.venv/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_make_test_folds\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0mallowed_target_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'binary'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'multiclass'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype_of_target_y\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_target_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    646\u001b[0m                 'Supported target types are: {}. Got {!r} instead.'.format(\n\u001b[1;32m    647\u001b[0m                     allowed_target_types, type_of_target_y))\n",
      "\u001b[0;31mValueError\u001b[0m: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead."
     ]
    }
   ],
   "source": [
    "\n",
    "train_data = lgb.Dataset(x, label=y)\n",
    "tscv = TimeSeriesSplit()\n",
    "param = {\n",
    "    'device_type': 'gpu',\n",
    "    'objective': 'binary',\n",
    "    'boosting': 'gbdt',\n",
    "    # 'metric': 'kullback_leibler',\n",
    "    # 'metric': 'auc',\n",
    "    # 'is_unbalance': True,\n",
    "}\n",
    "bst = lgb.cv(param, train_data)\n",
    "bst.save_model('model.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/trainer/train.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# 'is_unbalance': True,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m }\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/.venv/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, train_set, num_boost_round, folds, nfold, stratified, shuffle, metrics, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, fpreproc, verbose_eval, show_stdv, seed, callbacks, eval_train_metric, return_cvbooster)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m     cvfolds = _make_n_folds(train_set, folds=folds, nfold=nfold,\n\u001b[0m\u001b[1;32m    561\u001b[0m                             \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpreproc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfpreproc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                             \u001b[0mstratified\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratified\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/.venv/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36m_make_n_folds\u001b[0;34m(full_data, folds, nfold, params, seed, fpreproc, stratified, shuffle, eval_train_metric)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCVBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m         \u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0mvalid_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/.venv/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    330\u001b[0m                 .format(self.n_splits, n_samples))\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/.venv/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0mtrain_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mtest_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/.venv/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_test_masks\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m         \u001b[0mtest_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_folds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtest_folds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/.venv/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_make_test_folds\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0mallowed_target_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'binary'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'multiclass'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype_of_target_y\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_target_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    646\u001b[0m                 'Supported target types are: {}. Got {!r} instead.'.format(\n\u001b[1;32m    647\u001b[0m                     allowed_target_types, type_of_target_y))\n",
      "\u001b[0;31mValueError\u001b[0m: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead."
     ]
    }
   ],
   "source": [
    "\n",
    "train_data = lgb.Dataset(x, label=y)\n",
    "tscv = TimeSeriesSplit()\n",
    "param = {\n",
    "    'device_type': 'gpu',\n",
    "    'application': 'binary',\n",
    "    'boosting': 'gbdt',\n",
    "    # 'metric': 'kullback_leibler',\n",
    "    # 'metric': 'auc',\n",
    "    # 'is_unbalance': True,\n",
    "}\n",
    "bst = lgb.cv(param, train_data)\n",
    "bst.save_model('model.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/trainer/train.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# 'is_unbalance': True,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m }\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/.venv/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, train_set, num_boost_round, folds, nfold, stratified, shuffle, metrics, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, fpreproc, verbose_eval, show_stdv, seed, callbacks, eval_train_metric, return_cvbooster)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m     cvfolds = _make_n_folds(train_set, folds=folds, nfold=nfold,\n\u001b[0m\u001b[1;32m    561\u001b[0m                             \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpreproc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfpreproc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                             \u001b[0mstratified\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratified\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/.venv/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36m_make_n_folds\u001b[0;34m(full_data, folds, nfold, params, seed, fpreproc, stratified, shuffle, eval_train_metric)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCVBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m         \u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0mvalid_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/.venv/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    330\u001b[0m                 .format(self.n_splits, n_samples))\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/.venv/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0mtrain_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mtest_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/.venv/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_test_masks\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m         \u001b[0mtest_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_folds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtest_folds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/.venv/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_make_test_folds\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0mallowed_target_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'binary'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'multiclass'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype_of_target_y\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_target_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    646\u001b[0m                 'Supported target types are: {}. Got {!r} instead.'.format(\n\u001b[1;32m    647\u001b[0m                     allowed_target_types, type_of_target_y))\n",
      "\u001b[0;31mValueError\u001b[0m: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead."
     ]
    }
   ],
   "source": [
    "\n",
    "train_data = lgb.Dataset(x, label=y)\n",
    "tscv = TimeSeriesSplit()\n",
    "param = {\n",
    "    'device_type': 'gpu',\n",
    "    'application': 'binary',\n",
    "    'objective': 'binary',\n",
    "    'boosting': 'gbdt',\n",
    "    # 'metric': 'kullback_leibler',\n",
    "    # 'metric': 'auc',\n",
    "    # 'is_unbalance': True,\n",
    "}\n",
    "bst = lgb.cv(param, train_data)\n",
    "bst.save_model('model.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/trainer/train.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# 'is_unbalance': True,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m }\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratified\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/.venv/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, train_set, num_boost_round, folds, nfold, stratified, shuffle, metrics, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, fpreproc, verbose_eval, show_stdv, seed, callbacks, eval_train_metric, return_cvbooster)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m     cvfolds = _make_n_folds(train_set, folds=folds, nfold=nfold,\n\u001b[0m\u001b[1;32m    561\u001b[0m                             \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpreproc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfpreproc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                             \u001b[0mstratified\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratified\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/.venv/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36m_make_n_folds\u001b[0;34m(full_data, folds, nfold, params, seed, fpreproc, stratified, shuffle, eval_train_metric)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCVBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m         \u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0mvalid_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/.venv/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    330\u001b[0m                 .format(self.n_splits, n_samples))\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/.venv/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0mtrain_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mtest_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/.venv/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_test_masks\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m         \u001b[0mtest_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_folds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtest_folds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/.venv/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_make_test_folds\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0mallowed_target_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'binary'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'multiclass'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype_of_target_y\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_target_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    646\u001b[0m                 'Supported target types are: {}. Got {!r} instead.'.format(\n\u001b[1;32m    647\u001b[0m                     allowed_target_types, type_of_target_y))\n",
      "\u001b[0;31mValueError\u001b[0m: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead."
     ]
    }
   ],
   "source": [
    "\n",
    "train_data = lgb.Dataset(x, label=y)\n",
    "tscv = TimeSeriesSplit()\n",
    "param = {\n",
    "    'device_type': 'gpu',\n",
    "    'application': 'binary',\n",
    "    'objective': 'binary',\n",
    "    'boosting': 'gbdt',\n",
    "    # 'metric': 'kullback_leibler',\n",
    "    # 'metric': 'auc',\n",
    "    # 'is_unbalance': True,\n",
    "}\n",
    "bst = lgb.cv(param, train_data, stratified=True)\n",
    "bst.save_model('model.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n",
      "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n",
      "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n",
      "[LightGBM] [Info] Number of positive: 1502, number of negative: 746\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 196270\n",
      "[LightGBM] [Info] Number of data points in the train set: 2248, number of used features: 773\n",
      "[LightGBM] [Info] Using GPU Device: GeForce GTX TITAN X, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 772 dense feature groups (1.66 MB) transferred to GPU in 0.011914 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n",
      "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n",
      "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n",
      "[LightGBM] [Info] Number of positive: 1506, number of negative: 742\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 196270\n",
      "[LightGBM] [Info] Number of data points in the train set: 2248, number of used features: 773\n",
      "[LightGBM] [Info] Using GPU Device: GeForce GTX TITAN X, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 772 dense feature groups (1.66 MB) transferred to GPU in 0.009554 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n",
      "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n",
      "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n",
      "[LightGBM] [Info] Number of positive: 1497, number of negative: 751\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 196270\n",
      "[LightGBM] [Info] Number of data points in the train set: 2248, number of used features: 773\n",
      "[LightGBM] [Info] Using GPU Device: GeForce GTX TITAN X, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 772 dense feature groups (1.66 MB) transferred to GPU in 0.010652 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n",
      "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n",
      "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n",
      "[LightGBM] [Info] Number of positive: 1492, number of negative: 756\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 196270\n",
      "[LightGBM] [Info] Number of data points in the train set: 2248, number of used features: 773\n",
      "[LightGBM] [Info] Using GPU Device: GeForce GTX TITAN X, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 772 dense feature groups (1.66 MB) transferred to GPU in 0.011574 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n",
      "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n",
      "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n",
      "[LightGBM] [Info] Number of positive: 1495, number of negative: 753\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 196270\n",
      "[LightGBM] [Info] Number of data points in the train set: 2248, number of used features: 773\n",
      "[LightGBM] [Info] Using GPU Device: GeForce GTX TITAN X, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 772 dense feature groups (1.66 MB) transferred to GPU in 0.010370 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.668149 -> initscore=0.699827\n",
      "[LightGBM] [Info] Start training from score 0.699827\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669929 -> initscore=0.707863\n",
      "[LightGBM] [Info] Start training from score 0.707863\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.665925 -> initscore=0.689813\n",
      "[LightGBM] [Info] Start training from score 0.689813\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.663701 -> initscore=0.679831\n",
      "[LightGBM] [Info] Start training from score 0.679831\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.665036 -> initscore=0.685816\n",
      "[LightGBM] [Info] Start training from score 0.685816\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'save_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/trainer/train.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m }\n\u001b[1;32m     12\u001b[0m \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratified\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'save_model'"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data = lgb.Dataset(x, label=y)\n",
    "tscv = TimeSeriesSplit()\n",
    "param = {\n",
    "    'device_type': 'gpu',\n",
    "    'application': 'binary',\n",
    "    'objective': 'binary',\n",
    "    'boosting': 'gbdt',\n",
    "    # 'metric': 'kullback_leibler',\n",
    "    # 'metric': 'auc',\n",
    "    # 'is_unbalance': True,\n",
    "}\n",
    "bst = lgb.cv(param, train_data, stratified=False)\n",
    "bst.save_model('model.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'binary_logloss-mean': [0.5419050144040132,\n",
       "  0.4678303486639841,\n",
       "  0.40766557424529504,\n",
       "  0.35759710686370194,\n",
       "  0.3152334107746819,\n",
       "  0.2789936203600265,\n",
       "  0.2477239326900103,\n",
       "  0.2205311922207521,\n",
       "  0.19676724985788857,\n",
       "  0.1758975159446327,\n",
       "  0.15748384461646853,\n",
       "  0.1412029826173551,\n",
       "  0.12676307945210202,\n",
       "  0.11392718371784691,\n",
       "  0.10250583265339212,\n",
       "  0.09230556087638166,\n",
       "  0.08320573867722367,\n",
       "  0.07505542444115616,\n",
       "  0.06775406354010602,\n",
       "  0.061212839259827456,\n",
       "  0.05533697611487011,\n",
       "  0.050067197135826746,\n",
       "  0.04533716807942591,\n",
       "  0.04107794435593198,\n",
       "  0.037247179943606115,\n",
       "  0.033800760702800345,\n",
       "  0.03069872728548404,\n",
       "  0.027898752773622103,\n",
       "  0.025382539241594164,\n",
       "  0.023101971703033033,\n",
       "  0.021059066436211613,\n",
       "  0.019211651025470698,\n",
       "  0.017542998626524472,\n",
       "  0.016041413229348447,\n",
       "  0.014698244633537225,\n",
       "  0.013477037176613384,\n",
       "  0.012385149007592824,\n",
       "  0.011392986757127655,\n",
       "  0.010504648645798021,\n",
       "  0.00969426656877272,\n",
       "  0.0089548163937035,\n",
       "  0.008293090334995219,\n",
       "  0.007698694000201872,\n",
       "  0.007165188827674272,\n",
       "  0.006686748306119298,\n",
       "  0.0062581195674717245,\n",
       "  0.00587456745572273,\n",
       "  0.005531827503045837,\n",
       "  0.005226045978546573,\n",
       "  0.0049537600574515684,\n",
       "  0.004712173024249748,\n",
       "  0.004498817157603183,\n",
       "  0.004310245103359177,\n",
       "  0.004143941345708909,\n",
       "  0.003998547494421979,\n",
       "  0.0038718997389642434,\n",
       "  0.003763059815384649,\n",
       "  0.0036683365315308422,\n",
       "  0.0035880980073776368,\n",
       "  0.0035209751148036926,\n",
       "  0.003465637613625624,\n",
       "  0.0034213360890031656,\n",
       "  0.003387191475329631,\n",
       "  0.0033621345358578443,\n",
       "  0.00334595223429482,\n",
       "  0.0033377890466016885,\n",
       "  0.0033369656521729852,\n",
       "  0.0033431963706133322,\n",
       "  0.0033556045909360157,\n",
       "  0.0033742278780592794,\n",
       "  0.0033984532092148556,\n",
       "  0.003427711034703536,\n",
       "  0.0034621737394577045,\n",
       "  0.0035014654820254543,\n",
       "  0.0035450183723418904,\n",
       "  0.0035929281630438055,\n",
       "  0.003644625810104172,\n",
       "  0.0037000379959615535,\n",
       "  0.003759212785115489,\n",
       "  0.0038216788720687456,\n",
       "  0.003887227971297353,\n",
       "  0.003955728611952569,\n",
       "  0.004027079613324826,\n",
       "  0.0041010275253347325,\n",
       "  0.004177512780926924,\n",
       "  0.004256321304900724,\n",
       "  0.004337389099328619,\n",
       "  0.0044205262770688515,\n",
       "  0.004505428354463796,\n",
       "  0.004592118302762257,\n",
       "  0.004680465581379521,\n",
       "  0.004770378586183196,\n",
       "  0.004861720715675939,\n",
       "  0.00495431744015872,\n",
       "  0.005048118136478691,\n",
       "  0.005143066906436769,\n",
       "  0.005239019134554169,\n",
       "  0.005335928283688537,\n",
       "  0.005433709098448156,\n",
       "  0.005532325812454763],\n",
       " 'binary_logloss-stdv': [0.00463486912617994,\n",
       "  0.0036671845917390826,\n",
       "  0.002968257401690479,\n",
       "  0.002482720629303668,\n",
       "  0.002147714318556637,\n",
       "  0.001905348275804841,\n",
       "  0.0017135930161317277,\n",
       "  0.0015899312490737286,\n",
       "  0.0014840224702057847,\n",
       "  0.0014374972888811686,\n",
       "  0.0014039142004786274,\n",
       "  0.001392323827432706,\n",
       "  0.0013979549656924508,\n",
       "  0.0014217444316037718,\n",
       "  0.001443674101006952,\n",
       "  0.0014823800331390195,\n",
       "  0.0015191945415423105,\n",
       "  0.0015712463572785636,\n",
       "  0.0016264451088762789,\n",
       "  0.0016832208326725722,\n",
       "  0.0017462016946181106,\n",
       "  0.0018059033680714476,\n",
       "  0.0018633663507556487,\n",
       "  0.0019266666224371355,\n",
       "  0.0019915349612561147,\n",
       "  0.0020565172813578575,\n",
       "  0.0021226309268623784,\n",
       "  0.002193750066601611,\n",
       "  0.0022612856585666765,\n",
       "  0.002335654359512059,\n",
       "  0.002405217726481213,\n",
       "  0.002479493142728198,\n",
       "  0.002554359715705647,\n",
       "  0.0026279666335422085,\n",
       "  0.0026959097157083973,\n",
       "  0.002770188882212154,\n",
       "  0.0028405511645918074,\n",
       "  0.0029152946373467345,\n",
       "  0.0029871326719140396,\n",
       "  0.003064079471429565,\n",
       "  0.0031458236883114984,\n",
       "  0.003224927079442605,\n",
       "  0.0033030605804093573,\n",
       "  0.0033802863654069483,\n",
       "  0.003456665504195131,\n",
       "  0.003532254868322872,\n",
       "  0.0036071009742850435,\n",
       "  0.0036812423765648855,\n",
       "  0.0037547162758974997,\n",
       "  0.003827550514363862,\n",
       "  0.0038995884307978647,\n",
       "  0.003970676240965434,\n",
       "  0.0040412808239153886,\n",
       "  0.0041115439005775635,\n",
       "  0.0041810994800783995,\n",
       "  0.004250111425507263,\n",
       "  0.00431819566960706,\n",
       "  0.004386499689888909,\n",
       "  0.004454115789695224,\n",
       "  0.00452112177602979,\n",
       "  0.004587640537938889,\n",
       "  0.004653539918207732,\n",
       "  0.004718813254289676,\n",
       "  0.004783604576572272,\n",
       "  0.004847639317769766,\n",
       "  0.004911032001490639,\n",
       "  0.004973841076197197,\n",
       "  0.005035937842522163,\n",
       "  0.0050975559933908645,\n",
       "  0.005158447240588655,\n",
       "  0.005218750728607654,\n",
       "  0.005278612764471084,\n",
       "  0.005337768426807247,\n",
       "  0.005396289024032204,\n",
       "  0.0054543767637357295,\n",
       "  0.005511856033371888,\n",
       "  0.005568966197619701,\n",
       "  0.00562565923214305,\n",
       "  0.005681817894474867,\n",
       "  0.005737655909757026,\n",
       "  0.005793233751054123,\n",
       "  0.005848570864924616,\n",
       "  0.005903669440460788,\n",
       "  0.005958637696240602,\n",
       "  0.006013460829844083,\n",
       "  0.006068228173101762,\n",
       "  0.006122930551533743,\n",
       "  0.0061776477955217185,\n",
       "  0.006232542649637314,\n",
       "  0.006287553249580191,\n",
       "  0.006342724491873408,\n",
       "  0.006398075605241267,\n",
       "  0.006453656539749564,\n",
       "  0.006509550899294244,\n",
       "  0.00656575279066909,\n",
       "  0.00662225823592035,\n",
       "  0.006679133775920837,\n",
       "  0.0067363715599594795,\n",
       "  0.006793996661111789,\n",
       "  0.006851991751328622]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['binary_logloss-mean', 'binary_logloss-stdv'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1502, number of negative: 746\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 196270\n",
      "[LightGBM] [Info] Number of data points in the train set: 2248, number of used features: 773\n",
      "[LightGBM] [Info] Using GPU Device: GeForce GTX TITAN X, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 772 dense feature groups (1.66 MB) transferred to GPU in 0.008896 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Number of positive: 1506, number of negative: 742\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 196270\n",
      "[LightGBM] [Info] Number of data points in the train set: 2248, number of used features: 773\n",
      "[LightGBM] [Info] Using GPU Device: GeForce GTX TITAN X, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 772 dense feature groups (1.66 MB) transferred to GPU in 0.008901 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Number of positive: 1497, number of negative: 751\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 196270\n",
      "[LightGBM] [Info] Number of data points in the train set: 2248, number of used features: 773\n",
      "[LightGBM] [Info] Using GPU Device: GeForce GTX TITAN X, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 772 dense feature groups (1.66 MB) transferred to GPU in 0.007232 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Number of positive: 1492, number of negative: 756\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 196270\n",
      "[LightGBM] [Info] Number of data points in the train set: 2248, number of used features: 773\n",
      "[LightGBM] [Info] Using GPU Device: GeForce GTX TITAN X, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 772 dense feature groups (1.66 MB) transferred to GPU in 0.006752 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Number of positive: 1495, number of negative: 753\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 196270\n",
      "[LightGBM] [Info] Number of data points in the train set: 2248, number of used features: 773\n",
      "[LightGBM] [Info] Using GPU Device: GeForce GTX TITAN X, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 772 dense feature groups (1.66 MB) transferred to GPU in 0.010716 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.668149 -> initscore=0.699827\n",
      "[LightGBM] [Info] Start training from score 0.699827\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669929 -> initscore=0.707863\n",
      "[LightGBM] [Info] Start training from score 0.707863\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.665925 -> initscore=0.689813\n",
      "[LightGBM] [Info] Start training from score 0.689813\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.663701 -> initscore=0.679831\n",
      "[LightGBM] [Info] Start training from score 0.679831\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.665036 -> initscore=0.685816\n",
      "[LightGBM] [Info] Start training from score 0.685816\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'save_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/trainer/train.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m }\n\u001b[1;32m     11\u001b[0m \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratified\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_cvbooster\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'save_model'"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data = lgb.Dataset(x, label=y)\n",
    "tscv = TimeSeriesSplit()\n",
    "param = {\n",
    "    'device_type': 'gpu',\n",
    "    'objective': 'binary',\n",
    "    'boosting': 'gbdt',\n",
    "    # 'metric': 'kullback_leibler',\n",
    "    # 'metric': 'auc',\n",
    "    # 'is_unbalance': True,\n",
    "}\n",
    "bst = lgb.cv(param, train_data, stratified=False, return_cvbooster=True)\n",
    "bst.save_model('model.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['binary_logloss-mean', 'binary_logloss-stdv', 'cvbooster'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'cvbooster'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/trainer/train.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvbooster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'cvbooster'"
     ]
    }
   ],
   "source": [
    "bst.cvbooster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.engine.CVBooster at 0x7fd41c7c9070>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst['cvbooster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function lightgbm.engine.CVBooster.__getattr__.<locals>.handler_function(*args, **kwargs)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst['cvbooster'].save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1502, number of negative: 746\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 196270\n",
      "[LightGBM] [Info] Number of data points in the train set: 2248, number of used features: 773\n",
      "[LightGBM] [Info] Using GPU Device: GeForce GTX TITAN X, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 772 dense feature groups (1.66 MB) transferred to GPU in 0.007596 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Number of positive: 1506, number of negative: 742\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 196270\n",
      "[LightGBM] [Info] Number of data points in the train set: 2248, number of used features: 773\n",
      "[LightGBM] [Info] Using GPU Device: GeForce GTX TITAN X, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 772 dense feature groups (1.66 MB) transferred to GPU in 0.007964 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Number of positive: 1497, number of negative: 751\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 196270\n",
      "[LightGBM] [Info] Number of data points in the train set: 2248, number of used features: 773\n",
      "[LightGBM] [Info] Using GPU Device: GeForce GTX TITAN X, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 772 dense feature groups (1.66 MB) transferred to GPU in 0.010885 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Number of positive: 1492, number of negative: 756\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 196270\n",
      "[LightGBM] [Info] Number of data points in the train set: 2248, number of used features: 773\n",
      "[LightGBM] [Info] Using GPU Device: GeForce GTX TITAN X, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 772 dense feature groups (1.66 MB) transferred to GPU in 0.011571 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Number of positive: 1495, number of negative: 753\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 196270\n",
      "[LightGBM] [Info] Number of data points in the train set: 2248, number of used features: 773\n",
      "[LightGBM] [Info] Using GPU Device: GeForce GTX TITAN X, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 772 dense feature groups (1.66 MB) transferred to GPU in 0.011920 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.668149 -> initscore=0.699827\n",
      "[LightGBM] [Info] Start training from score 0.699827\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.669929 -> initscore=0.707863\n",
      "[LightGBM] [Info] Start training from score 0.707863\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.665925 -> initscore=0.689813\n",
      "[LightGBM] [Info] Start training from score 0.689813\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.663701 -> initscore=0.679831\n",
      "[LightGBM] [Info] Start training from score 0.679831\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.665036 -> initscore=0.685816\n",
      "[LightGBM] [Info] Start training from score 0.685816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<lightgbm.basic.Booster at 0x7fd51f74fa90>,\n",
       " <lightgbm.basic.Booster at 0x7fd4b6710f70>,\n",
       " <lightgbm.basic.Booster at 0x7fd51f74fd30>,\n",
       " <lightgbm.basic.Booster at 0x7fd4b672f280>,\n",
       " <lightgbm.basic.Booster at 0x7fd4b672f760>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_data = lgb.Dataset(x, label=y)\n",
    "tscv = TimeSeriesSplit()\n",
    "param = {\n",
    "    'device_type': 'gpu',\n",
    "    'objective': 'binary',\n",
    "    'boosting': 'gbdt',\n",
    "    # 'metric': 'kullback_leibler',\n",
    "    # 'metric': 'auc',\n",
    "    # 'is_unbalance': True,\n",
    "}\n",
    "bst = lgb.cv(param, train_data, stratified=False,\n",
    "             return_cvbooster=True)['cvbooster']\n",
    "bst.save_model('model.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KFold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/trainer/train.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                     \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                     folds=KFold(n_splits=3))\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'KFold' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data = lgb.Dataset(x, label=y)\n",
    "\n",
    "param = {\n",
    "    'device_type': 'gpu',\n",
    "    'objective': 'binary',\n",
    "    'boosting': 'gbdt',\n",
    "    \"verbosity\": -1,\n",
    "    # 'metric': 'kullback_leibler',\n",
    "    'metric': 'binary_logloss',\n",
    "    # 'is_unbalance': True,\n",
    "}\n",
    "bst = optuna_lgb.cv(param,\n",
    "                    train_data,\n",
    "                    stratified=False,\n",
    "                    verbose_eval=100,\n",
    "                    early_stopping_rounds=100,\n",
    "                    folds=KFold(n_splits=3))\n",
    "bst.save_model('model.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna.integration.lightgbm as optuna_lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math\n",
    "from operator import itemgetter\n",
    "import itertools\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "# https://gist.github.com/vbkaisetsu/d7c08e9c5aabe13686dd554ddfadf076\n",
    "def suffix_array(arr):\n",
    "    arr_size = len(arr)\n",
    "    arr_int = {v: k for k, v in enumerate(sorted(set(arr)))}\n",
    "    arr = [arr_int[x] for x in arr]\n",
    "    arr.append(-1)\n",
    "    suf = [[i, arr[i], arr[i + 1]] for i in range(arr_size)]\n",
    "    suf.sort(key=itemgetter(1, 2))\n",
    "    idx = [0] * arr_size\n",
    "    k = 2\n",
    "    while k < arr_size:\n",
    "        r = 0\n",
    "        prev_r = suf[0][1]\n",
    "        for i in range(arr_size):\n",
    "            if suf[i][1] != prev_r or suf[i - 1][2] != suf[i][2]:\n",
    "                r += 1\n",
    "            prev_r = suf[i][1]\n",
    "            suf[i][1] = r\n",
    "            idx[suf[i][0]] = i\n",
    "        for i in range(arr_size):\n",
    "            next_idx = suf[i][0] + k\n",
    "            suf[i][2] = suf[idx[next_idx]][1] if next_idx < arr_size else -1\n",
    "        suf.sort(key=itemgetter(1, 2))\n",
    "        k <<= 1\n",
    "    return [x[0] for x in suf]\n",
    "\n",
    "\n",
    "# https://gist.github.com/vbkaisetsu/d7c08e9c5aabe13686dd554ddfadf076\n",
    "def bwt_encode(data):\n",
    "    data_ref = suffix_array(data)\n",
    "    bwt_ref = (x - 1 for x in data_ref)\n",
    "    return ''.join([data[x] for x in bwt_ref])\n",
    "\n",
    "\n",
    "def balanced_bwt_rl_entropy(text):\n",
    "    rl_len = len([ch for ch, _ in itertools.groupby(bwt_encode(text))])\n",
    "    return math.exp(len(text) / rl_len)\n",
    "\n",
    "\n",
    "data_dir = '../data'\n",
    "train_data_path = join(data_dir, 'train.parquet')\n",
    "\n",
    "\n",
    "def loadData():\n",
    "    df = pd.read_parquet(train_data_path)\n",
    "    df.drop(columns=[\n",
    "        'id', 'authorName', 'authorPhoto', 'authorChannelId', 'timestampUsec',\n",
    "        'originChannelId', 'originVideoId', 'membership', 'purchase',\n",
    "        'rawMessage', 'message'\n",
    "    ],\n",
    "            inplace=True)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tcv_agg's binary_logloss: 15.0778 + 14.437\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'save_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/trainer/train.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m                     \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     folds=KFold(n_splits=3))\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'save_model'"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data = lgb.Dataset(x, label=y)\n",
    "\n",
    "param = {\n",
    "    'device_type': 'gpu',\n",
    "    'objective': 'binary',\n",
    "    'boosting': 'gbdt',\n",
    "    \"verbosity\": -1,\n",
    "    # 'metric': 'kullback_leibler',\n",
    "    'metric': 'binary_logloss',\n",
    "    # 'is_unbalance': True,\n",
    "}\n",
    "bst = optuna_lgb.cv(param,\n",
    "                    train_data,\n",
    "                    stratified=False,\n",
    "                    verbose_eval=100,\n",
    "                    early_stopping_rounds=100,\n",
    "                    folds=KFold(n_splits=3))\n",
    "bst.save_model('model.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "]\tcv_agg's binary_logloss: 15.0778 + 14.437\n",
      "[100]\tcv_agg's binary_logloss: 15.0778 + 14.437\n",
      "num_leaves, val_score: 11.978138:  65%|######5   | 13/20 [02:04<01:07,  9.70s/it]\u001b[32m[I 2021-01-22 16:14:55,166]\u001b[0m Trial 19 finished with value: 11.97813815920655 and parameters: {'num_leaves': 153}. Best is trial 7 with value: 11.97813815920655.\u001b[0m\n",
      "num_leaves, val_score: 11.978138:  70%|#######   | 14/20 [02:14<01:00, 10.02s/it]\u001b[32m[I 2021-01-22 16:15:05,924]\u001b[0m Trial 20 finished with value: 11.97813815920655 and parameters: {'num_leaves': 240}. Best is trial 7 with value: 11.97813815920655.\u001b[0m\n",
      "num_leaves, val_score: 11.978138:  70%|#######   | 14/20 [02:14<01:00, 10.02s/it][100]\tcv_agg's binary_logloss: 15.0778 + 14.437\n",
      "num_leaves, val_score: 11.978138:  75%|#######5  | 15/20 [02:24<00:49,  9.99s/it]\u001b[32m[I 2021-01-22 16:15:15,828]\u001b[0m Trial 21 finished with value: 11.97813815920655 and parameters: {'num_leaves': 98}. Best is trial 7 with value: 11.97813815920655.\u001b[0m\n",
      "num_leaves, val_score: 11.978138:  75%|#######5  | 15/20 [02:24<00:49,  9.99s/it][100]\tcv_agg's binary_logloss: 15.0778 + 14.437\n",
      "num_leaves, val_score: 11.978138:  80%|########  | 16/20 [02:35<00:40, 10.14s/it]\u001b[32m[I 2021-01-22 16:15:26,328]\u001b[0m Trial 22 finished with value: 11.97813815920655 and parameters: {'num_leaves': 211}. Best is trial 7 with value: 11.97813815920655.\u001b[0m\n",
      "num_leaves, val_score: 11.978138:  80%|########  | 16/20 [02:35<00:40, 10.14s/it][100]\tcv_agg's binary_logloss: 15.0778 + 14.437\n",
      "num_leaves, val_score: 11.978138:  85%|########5 | 17/20 [02:45<00:30, 10.07s/it]\u001b[32m[I 2021-01-22 16:15:36,223]\u001b[0m Trial 23 finished with value: 11.97813815920655 and parameters: {'num_leaves': 165}. Best is trial 7 with value: 11.97813815920655.\u001b[0m\n",
      "num_leaves, val_score: 11.978138:  85%|########5 | 17/20 [02:45<00:30, 10.07s/it][100]\tcv_agg's binary_logloss: 15.0778 + 14.437\n",
      "num_leaves, val_score: 11.978138:  90%|######### | 18/20 [02:55<00:20, 10.05s/it]\u001b[32m[I 2021-01-22 16:15:46,227]\u001b[0m Trial 24 finished with value: 11.97813815920655 and parameters: {'num_leaves': 93}. Best is trial 7 with value: 11.97813815920655.\u001b[0m\n",
      "num_leaves, val_score: 11.978138:  90%|######### | 18/20 [02:55<00:20, 10.05s/it][100]\tcv_agg's binary_logloss: 15.0778 + 14.437\n",
      "num_leaves, val_score: 11.978138:  95%|#########5| 19/20 [03:05<00:10, 10.14s/it]\u001b[32m[I 2021-01-22 16:15:56,577]\u001b[0m Trial 25 finished with value: 11.97813815920655 and parameters: {'num_leaves': 214}. Best is trial 7 with value: 11.97813815920655.\u001b[0m\n",
      "num_leaves, val_score: 11.978138:  95%|#########5| 19/20 [03:05<00:10, 10.14s/it][100]\tcv_agg's binary_logloss: 15.0778 + 14.437\n",
      "num_leaves, val_score: 11.978138: 100%|##########| 20/20 [03:15<00:00, 10.07s/it]\u001b[32m[I 2021-01-22 16:16:06,495]\u001b[0m Trial 26 finished with value: 11.97813815920655 and parameters: {'num_leaves': 181}. Best is trial 7 with value: 11.97813815920655.\u001b[0m\n",
      "num_leaves, val_score: 11.978138: 100%|##########| 20/20 [03:15<00:00,  9.77s/it]\n",
      "bagging, val_score: 11.978138:   0%|          | 0/10 [00:00<?, ?it/s][100]\tcv_agg's binary_logloss: 15.0778 + 14.437\n",
      "bagging, val_score: 11.978138:  10%|#         | 1/10 [00:04<00:36,  4.00s/it]\u001b[32m[I 2021-01-22 16:16:10,502]\u001b[0m Trial 27 finished with value: 11.97813815920655 and parameters: {'bagging_fraction': 0.520613885686388, 'bagging_freq': 7}. Best is trial 27 with value: 11.97813815920655.\u001b[0m\n",
      "bagging, val_score: 11.978138:  10%|#         | 1/10 [00:04<00:36,  4.00s/it][100]\tcv_agg's binary_logloss: 15.0778 + 14.437\n",
      "bagging, val_score: 11.978138:  20%|##        | 2/10 [00:08<00:33,  4.24s/it]\u001b[32m[I 2021-01-22 16:16:14,909]\u001b[0m Trial 28 finished with value: 11.97813815920655 and parameters: {'bagging_fraction': 0.7001577520808342, 'bagging_freq': 5}. Best is trial 27 with value: 11.97813815920655.\u001b[0m\n",
      "bagging, val_score: 11.978138:  20%|##        | 2/10 [00:08<00:33,  4.24s/it][100]\tcv_agg's binary_logloss: 15.0778 + 14.437\n",
      "bagging, val_score: 11.978138:  30%|###       | 3/10 [00:12<00:27,  3.97s/it]\u001b[32m[I 2021-01-22 16:16:18,555]\u001b[0m Trial 29 finished with value: 11.97813815920655 and parameters: {'bagging_fraction': 0.7444404667584404, 'bagging_freq': 6}. Best is trial 27 with value: 11.97813815920655.\u001b[0m\n",
      "bagging, val_score: 11.978138:  30%|###       | 3/10 [00:12<00:27,  3.97s/it][100]\tcv_agg's binary_logloss: 15.0778 + 14.437\n",
      "bagging, val_score: 11.978138:  40%|####      | 4/10 [00:17<00:26,  4.40s/it]\u001b[32m[I 2021-01-22 16:16:23,605]\u001b[0m Trial 30 finished with value: 11.97813815920655 and parameters: {'bagging_fraction': 0.7929818059135746, 'bagging_freq': 6}. Best is trial 27 with value: 11.97813815920655.\u001b[0m\n",
      "bagging, val_score: 11.978138:  40%|####      | 4/10 [00:17<00:26,  4.40s/it][100]\tcv_agg's binary_logloss: 15.0778 + 14.437\n",
      "bagging, val_score: 11.978138:  50%|#####     | 5/10 [00:21<00:22,  4.47s/it]\u001b[32m[I 2021-01-22 16:16:28,202]\u001b[0m Trial 31 finished with value: 11.97813815920655 and parameters: {'bagging_fraction': 0.8060734551720603, 'bagging_freq': 5}. Best is trial 27 with value: 11.97813815920655.\u001b[0m\n",
      "bagging, val_score: 11.978138:  50%|#####     | 5/10 [00:21<00:22,  4.47s/it][100]\tcv_agg's binary_logloss: 15.0778 + 14.437\n",
      "bagging, val_score: 11.978138:  60%|######    | 6/10 [00:26<00:17,  4.42s/it]\u001b[32m[I 2021-01-22 16:16:32,518]\u001b[0m Trial 32 finished with value: 11.97813815920655 and parameters: {'bagging_fraction': 0.8850213996302407, 'bagging_freq': 4}. Best is trial 27 with value: 11.97813815920655.\u001b[0m\n",
      "bagging, val_score: 11.978138:  60%|######    | 6/10 [00:26<00:17,  4.42s/it][100]\tcv_agg's binary_logloss: 15.0778 + 14.437\n",
      "bagging, val_score: 11.978138:  70%|#######   | 7/10 [00:29<00:12,  4.23s/it]\u001b[32m[I 2021-01-22 16:16:36,363]\u001b[0m Trial 33 finished with value: 11.97813815920655 and parameters: {'bagging_fraction': 0.5536310698672466, 'bagging_freq': 3}. Best is trial 27 with value: 11.97813815920655.\u001b[0m\n",
      "bagging, val_score: 11.978138:  70%|#######   | 7/10 [00:29<00:12,  4.23s/it][100]\tcv_agg's binary_logloss: 15.0778 + 14.437\n",
      "bagging, val_score: 11.978138:  80%|########  | 8/10 [00:34<00:08,  4.24s/it]\u001b[32m[I 2021-01-22 16:16:40,610]\u001b[0m Trial 34 finished with value: 11.97813815920655 and parameters: {'bagging_fraction': 0.8467351783092855, 'bagging_freq': 3}. Best is trial 27 with value: 11.97813815920655.\u001b[0m\n",
      "bagging, val_score: 11.978138:  80%|########  | 8/10 [00:34<00:08,  4.24s/it][100]\tcv_agg's binary_logloss: 15.0778 + 14.437\n",
      "bagging, val_score: 11.978138:  90%|######### | 9/10 [00:38<00:04,  4.24s/it]\u001b[32m[I 2021-01-22 16:16:44,858]\u001b[0m Trial 35 finished with value: 12.017571534704572 and parameters: {'bagging_fraction': 0.4645382048001193, 'bagging_freq': 3}. Best is trial 27 with value: 11.97813815920655.\u001b[0m\n",
      "bagging, val_score: 11.978138:  90%|######### | 9/10 [00:38<00:04,  4.24s/it][100]\tcv_agg's binary_logloss: 15.0778 + 14.437\n",
      "bagging, val_score: 11.978138: 100%|##########| 10/10 [00:42<00:00,  4.08s/it]\u001b[32m[I 2021-01-22 16:16:48,595]\u001b[0m Trial 36 finished with value: 11.97813815920655 and parameters: {'bagging_fraction': 0.8906526212073616, 'bagging_freq': 5}. Best is trial 27 with value: 11.97813815920655.\u001b[0m\n",
      "bagging, val_score: 11.978138: 100%|##########| 10/10 [00:42<00:00,  4.21s/it]\n",
      "feature_fraction_stage2, val_score: 11.978138:   0%|          | 0/3 [00:00<?, ?it/s][100]\tcv_agg's binary_logloss: 15.0778 + 14.437\n",
      "feature_fraction_stage2, val_score: 11.978138:  33%|###3      | 1/3 [00:03<00:07,  3.85s/it]\u001b[32m[I 2021-01-22 16:16:52,453]\u001b[0m Trial 37 finished with value: 11.97813815920655 and parameters: {'feature_fraction': 0.9520000000000001}. Best is trial 37 with value: 11.97813815920655.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 11.978138:  33%|###3      | 1/3 [00:03<00:07,  3.85s/it][100]\tcv_agg's binary_logloss: 15.0266 + 14.4527\n",
      "feature_fraction_stage2, val_score: 11.978138:  67%|######6   | 2/3 [00:07<00:03,  3.86s/it]\u001b[32m[I 2021-01-22 16:16:56,313]\u001b[0m Trial 38 finished with value: 11.982058529213703 and parameters: {'feature_fraction': 0.92}. Best is trial 37 with value: 11.97813815920655.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 11.978138:  67%|######6   | 2/3 [00:07<00:03,  3.86s/it][100]\tcv_agg's binary_logloss: 14.9975 + 14.4618\n",
      "feature_fraction_stage2, val_score: 11.978138: 100%|##########| 3/3 [00:11<00:00,  3.98s/it]\u001b[32m[I 2021-01-22 16:17:00,441]\u001b[0m Trial 39 finished with value: 11.97813815920655 and parameters: {'feature_fraction': 0.9840000000000001}. Best is trial 37 with value: 11.97813815920655.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 11.978138: 100%|##########| 3/3 [00:11<00:00,  3.95s/it]\n",
      "regularization_factors, val_score: 11.978138:   0%|          | 0/20 [00:00<?, ?it/s][100]\tcv_agg's binary_logloss: 15.0652 + 14.4409\n",
      "regularization_factors, val_score: 11.978138:   5%|5         | 1/20 [00:00<00:18,  1.04it/s]\u001b[32m[I 2021-01-22 16:17:01,409]\u001b[0m Trial 40 finished with value: 11.978143298171588 and parameters: {'lambda_l1': 0.003131763074941488, 'lambda_l2': 3.524901202346533e-06}. Best is trial 40 with value: 11.978143298171588.\u001b[0m\n",
      "regularization_factors, val_score: 11.978138:   5%|5         | 1/20 [00:00<00:18,  1.04it/s][100]\tcv_agg's binary_logloss: 15.0327 + 14.4508\n",
      "regularization_factors, val_score: 11.978138:  10%|#         | 2/20 [00:01<00:13,  1.30it/s]\u001b[32m[I 2021-01-22 16:17:02,043]\u001b[0m Trial 41 finished with value: 11.978138695883032 and parameters: {'lambda_l1': 3.2429075962512587e-06, 'lambda_l2': 0.000162280674882191}. Best is trial 41 with value: 11.978138695883032.\u001b[0m\n",
      "regularization_factors, val_score: 11.978138:  10%|#         | 2/20 [00:01<00:13,  1.30it/s][100]\tcv_agg's binary_logloss: 15.0753 + 14.4378\n",
      "regularization_factors, val_score: 11.978138:  15%|#5        | 3/20 [00:02<00:13,  1.27it/s]\u001b[32m[I 2021-01-22 16:17:02,846]\u001b[0m Trial 42 finished with value: 11.98064471680221 and parameters: {'lambda_l1': 1.5233359003029965, 'lambda_l2': 3.1869654462175675e-08}. Best is trial 41 with value: 11.978138695883032.\u001b[0m\n",
      "regularization_factors, val_score: 11.978138:  15%|#5        | 3/20 [00:02<00:13,  1.27it/s][100]\tcv_agg's binary_logloss: 13.6568 + 14.9917\n",
      "regularization_factors, val_score: 11.978138:  20%|##        | 4/20 [00:03<00:12,  1.30it/s]\u001b[32m[I 2021-01-22 16:17:03,590]\u001b[0m Trial 43 finished with value: 11.97813817362976 and parameters: {'lambda_l1': 1.0011162014180307e-08, 'lambda_l2': 4.399795312095966e-06}. Best is trial 43 with value: 11.97813817362976.\u001b[0m\n",
      "regularization_factors, val_score: 11.978138:  20%|##        | 4/20 [00:03<00:12,  1.30it/s][100]\tcv_agg's binary_logloss: 15.0777 + 14.437\n",
      "regularization_factors, val_score: 11.978138:  25%|##5       | 5/20 [00:03<00:10,  1.40it/s]\u001b[32m[I 2021-01-22 16:17:04,202]\u001b[0m Trial 44 finished with value: 11.978138753646894 and parameters: {'lambda_l1': 0.00031093178450727866, 'lambda_l2': 2.6074465717330285e-05}. Best is trial 43 with value: 11.97813817362976.\u001b[0m\n",
      "regularization_factors, val_score: 11.978138:  25%|##5       | 5/20 [00:03<00:10,  1.40it/s][100]\tcv_agg's binary_logloss: 15.0727 + 14.4386\n",
      "regularization_factors, val_score: 11.978138:  30%|###       | 6/20 [00:04<00:09,  1.40it/s]\u001b[32m[I 2021-01-22 16:17:04,916]\u001b[0m Trial 45 finished with value: 11.983595411749606 and parameters: {'lambda_l1': 3.113071014738617e-06, 'lambda_l2': 2.0578692633792763}. Best is trial 43 with value: 11.97813817362976.\u001b[0m\n",
      "regularization_factors, val_score: 11.978138:  30%|###       | 6/20 [00:04<00:09,  1.40it/s][100]\tcv_agg's binary_logloss: 13.9607 + 14.8547\n",
      "regularization_factors, val_score: 11.978138:  35%|###5      | 7/20 [00:05<00:08,  1.45it/s]\u001b[32m[I 2021-01-22 16:17:05,553]\u001b[0m Trial 46 finished with value: 11.980399744363018 and parameters: {'lambda_l1': 1.3751225457704193, 'lambda_l2': 1.539273675317962e-06}. Best is trial 43 with value: 11.97813817362976.\u001b[0m\n",
      "regularization_factors, val_score: 11.978138:  35%|###5      | 7/20 [00:05<00:08,  1.45it/s][100]\tcv_agg's binary_logloss: 13.6891 + 14.9768\n",
      "regularization_factors, val_score: 11.978138:  40%|####      | 8/20 [00:05<00:07,  1.50it/s]\u001b[32m[I 2021-01-22 16:17:06,173]\u001b[0m Trial 47 finished with value: 11.980057486218499 and parameters: {'lambda_l1': 1.1678149555823936, 'lambda_l2': 6.778700234854301e-08}. Best is trial 43 with value: 11.97813817362976.\u001b[0m\n",
      "regularization_factors, val_score: 11.978138:  40%|####      | 8/20 [00:05<00:07,  1.50it/s][100]\tcv_agg's binary_logloss: 13.7406 + 14.953\n",
      "regularization_factors, val_score: 11.978138:  45%|####5     | 9/20 [00:06<00:07,  1.50it/s]\u001b[32m[I 2021-01-22 16:17:06,841]\u001b[0m Trial 48 finished with value: 11.979289414750637 and parameters: {'lambda_l1': 0.016376769015535603, 'lambda_l2': 0.35760455964792115}. Best is trial 43 with value: 11.97813817362976.\u001b[0m\n",
      "regularization_factors, val_score: 11.978138:  45%|####5     | 9/20 [00:06<00:07,  1.50it/s][100]\tcv_agg's binary_logloss: 14.3625 + 14.6869\n",
      "regularization_factors, val_score: 11.978138:  50%|#####     | 10/20 [00:07<00:06,  1.51it/s]\u001b[32m[I 2021-01-22 16:17:07,488]\u001b[0m Trial 49 finished with value: 11.978139011547215 and parameters: {'lambda_l1': 0.0005084256826151329, 'lambda_l2': 6.088770634486517e-06}. Best is trial 43 with value: 11.97813817362976.\u001b[0m\n",
      "regularization_factors, val_score: 11.978138:  50%|#####     | 10/20 [00:07<00:06,  1.51it/s][100]\tcv_agg's binary_logloss: 15.07 + 14.4394\n",
      "regularization_factors, val_score: 11.978138:  55%|#####5    | 11/20 [00:07<00:05,  1.54it/s]\u001b[32m[I 2021-01-22 16:17:08,109]\u001b[0m Trial 50 finished with value: 11.978149387349896 and parameters: {'lambda_l1': 1.191458714066222e-08, 'lambda_l2': 0.0034303581231968873}. Best is trial 43 with value: 11.97813817362976.\u001b[0m\n",
      "regularization_factors, val_score: 11.978138:  55%|#####5    | 11/20 [00:07<00:05,  1.54it/s][100]\tcv_agg's binary_logloss: 15.0317 + 14.4511\n",
      "regularization_factors, val_score: 11.978138:  60%|######    | 12/20 [00:08<00:05,  1.53it/s]\u001b[32m[I 2021-01-22 16:17:08,774]\u001b[0m Trial 51 finished with value: 11.978144748772882 and parameters: {'lambda_l1': 2.7335552461990143e-08, 'lambda_l2': 0.0020128743260078674}. Best is trial 43 with value: 11.97813817362976.\u001b[0m\n",
      "regularization_factors, val_score: 11.978138:  60%|######    | 12/20 [00:08<00:05,  1.53it/s][100]\tcv_agg's binary_logloss: 15.0493 + 14.4457\n",
      "regularization_factors, val_score: 11.978138:  65%|######5   | 13/20 [00:09<00:04,  1.45it/s]\u001b[32m[I 2021-01-22 16:17:09,540]\u001b[0m Trial 52 finished with value: 11.978138560140048 and parameters: {'lambda_l1': 7.405360436741982e-07, 'lambda_l2': 0.00012207511299953193}. Best is trial 43 with value: 11.97813817362976.\u001b[0m\n",
      "regularization_factors, val_score: 11.978138:  65%|######5   | 13/20 [00:09<00:04,  1.45it/s][100]\tcv_agg's binary_logloss: 15.0759 + 14.4376\n",
      "regularization_factors, val_score: 11.978138:  70%|#######   | 14/20 [00:09<00:04,  1.37it/s]\u001b[32m[I 2021-01-22 16:17:10,363]\u001b[0m Trial 53 finished with value: 11.978306714493577 and parameters: {'lambda_l1': 3.272483164277655e-07, 'lambda_l2': 0.05177706587434326}. Best is trial 43 with value: 11.97813817362976.\u001b[0m\n",
      "regularization_factors, val_score: 11.978138:  70%|#######   | 14/20 [00:09<00:04,  1.37it/s][100]\tcv_agg's binary_logloss: 14.7638 + 14.5387\n",
      "regularization_factors, val_score: 11.978138:  75%|#######5  | 15/20 [00:11<00:04,  1.08it/s]\u001b[32m[I 2021-01-22 16:17:11,746]\u001b[0m Trial 54 finished with value: 11.978138161053382 and parameters: {'lambda_l1': 2.387031071859097e-07, 'lambda_l2': 4.446648552561655e-07}. Best is trial 54 with value: 11.978138161053382.\u001b[0m\n",
      "regularization_factors, val_score: 11.978138:  75%|#######5  | 15/20 [00:11<00:04,  1.08it/s][100]\tcv_agg's binary_logloss: 15.0778 + 14.437\n",
      "regularization_factors, val_score: 11.978138:  80%|########  | 16/20 [00:12<00:03,  1.11it/s]\u001b[32m[I 2021-01-22 16:17:12,602]\u001b[0m Trial 55 finished with value: 11.978138159784628 and parameters: {'lambda_l1': 1.0443407029517616e-08, 'lambda_l2': 1.7132083335689268e-07}. Best is trial 55 with value: 11.978138159784628.\u001b[0m\n",
      "regularization_factors, val_score: 11.978138:  80%|########  | 16/20 [00:12<00:03,  1.11it/s][100]\tcv_agg's binary_logloss: 15.0778 + 14.437\n",
      "regularization_factors, val_score: 11.978138:  85%|########5 | 17/20 [00:13<00:02,  1.11it/s]\u001b[32m[I 2021-01-22 16:17:13,502]\u001b[0m Trial 56 finished with value: 11.978138160473067 and parameters: {'lambda_l1': 9.052211697351825e-08, 'lambda_l2': 3.415299802090634e-07}. Best is trial 55 with value: 11.978138159784628.\u001b[0m\n",
      "regularization_factors, val_score: 11.978138:  85%|########5 | 17/20 [00:13<00:02,  1.11it/s][100]\tcv_agg's binary_logloss: 15.0778 + 14.437\n",
      "regularization_factors, val_score: 11.978138:  90%|######### | 18/20 [00:13<00:01,  1.20it/s]\u001b[32m[I 2021-01-22 16:17:14,168]\u001b[0m Trial 57 finished with value: 11.978138220368272 and parameters: {'lambda_l1': 3.710194771069004e-05, 'lambda_l2': 1.276007260289525e-07}. Best is trial 55 with value: 11.978138159784628.\u001b[0m\n",
      "regularization_factors, val_score: 11.978138:  90%|######### | 18/20 [00:13<00:01,  1.20it/s][100]\tcv_agg's binary_logloss: 15.0772 + 14.4372\n",
      "regularization_factors, val_score: 11.978138:  95%|#########5| 19/20 [00:14<00:00,  1.12it/s]\u001b[32m[I 2021-01-22 16:17:15,213]\u001b[0m Trial 58 finished with value: 11.978138159313884 and parameters: {'lambda_l1': 2.8421327506773812e-08, 'lambda_l2': 1.8569518607676103e-08}. Best is trial 58 with value: 11.978138159313884.\u001b[0m\n",
      "regularization_factors, val_score: 11.978138:  95%|#########5| 19/20 [00:14<00:00,  1.12it/s][100]\tcv_agg's binary_logloss: 15.0778 + 14.437\n",
      "regularization_factors, val_score: 11.978138: 100%|##########| 20/20 [00:15<00:00,  1.21it/s]\u001b[32m[I 2021-01-22 16:17:15,880]\u001b[0m Trial 59 finished with value: 11.97813817420778 and parameters: {'lambda_l1': 9.1159597499281e-06, 'lambda_l2': 2.3343753963272795e-08}. Best is trial 58 with value: 11.978138159313884.\u001b[0m\n",
      "regularization_factors, val_score: 11.978138: 100%|##########| 20/20 [00:15<00:00,  1.30it/s]\n",
      "min_data_in_leaf, val_score: 11.978138:   0%|          | 0/5 [00:00<?, ?it/s][100]\tcv_agg's binary_logloss: 15.0777 + 14.437\n",
      "min_data_in_leaf, val_score: 11.978138:  20%|##        | 1/5 [00:03<00:15,  3.86s/it]\u001b[32m[I 2021-01-22 16:17:19,748]\u001b[0m Trial 60 finished with value: 11.97813815920655 and parameters: {'min_child_samples': 10}. Best is trial 60 with value: 11.97813815920655.\u001b[0m\n",
      "min_data_in_leaf, val_score: 11.978138:  20%|##        | 1/5 [00:03<00:15,  3.86s/it][100]\tcv_agg's binary_logloss: 15.0778 + 14.437\n",
      "min_data_in_leaf, val_score: 11.978138:  40%|####      | 2/5 [00:08<00:12,  4.11s/it]\u001b[32m[I 2021-01-22 16:17:24,023]\u001b[0m Trial 61 finished with value: 11.97813815920655 and parameters: {'min_child_samples': 25}. Best is trial 60 with value: 11.97813815920655.\u001b[0m\n",
      "min_data_in_leaf, val_score: 11.978138:  40%|####      | 2/5 [00:08<00:12,  4.11s/it][100]\tcv_agg's binary_logloss: 15.0778 + 14.437\n",
      "min_data_in_leaf, val_score: 11.978138:  60%|######    | 3/5 [00:12<00:08,  4.29s/it]\u001b[32m[I 2021-01-22 16:17:28,526]\u001b[0m Trial 62 finished with value: 11.97813815920655 and parameters: {'min_child_samples': 5}. Best is trial 60 with value: 11.97813815920655.\u001b[0m\n",
      "min_data_in_leaf, val_score: 11.978138:  60%|######    | 3/5 [00:12<00:08,  4.29s/it][100]\tcv_agg's binary_logloss: 15.0778 + 14.437\n",
      "min_data_in_leaf, val_score: 11.978138:  80%|########  | 4/5 [00:15<00:03,  3.75s/it]\u001b[32m[I 2021-01-22 16:17:31,449]\u001b[0m Trial 63 finished with value: 12.033792342622327 and parameters: {'min_child_samples': 100}. Best is trial 60 with value: 11.97813815920655.\u001b[0m\n",
      "min_data_in_leaf, val_score: 11.978138:  80%|########  | 4/5 [00:15<00:03,  3.75s/it][100]\tcv_agg's binary_logloss: 15.0779 + 14.4369\n",
      "min_data_in_leaf, val_score: 11.978138: 100%|##########| 5/5 [00:19<00:00,  3.83s/it]\u001b[32m[I 2021-01-22 16:17:35,434]\u001b[0m Trial 64 finished with value: 12.024573098965533 and parameters: {'min_child_samples': 50}. Best is trial 60 with value: 11.97813815920655.\u001b[0m\n",
      "min_data_in_leaf, val_score: 11.978138: 100%|##########| 5/5 [00:19<00:00,  3.91s/it][100]\tcv_agg's binary_logloss: 15.0778 + 14.437\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "LightGBMTunerCV requires `return_cvbooster=True` for method `get_best_booster()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/trainer/train.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m                                    folds=KFold(n_splits=3))\n\u001b[1;32m     18\u001b[0m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_booster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/.venv/lib/python3.8/site-packages/optuna/integration/_lightgbm_tuner/optimize.py\u001b[0m in \u001b[0;36mget_best_booster\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \"\"\"\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgbm_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"return_cvbooster\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1025\u001b[0m                 \u001b[0;34m\"LightGBMTunerCV requires `return_cvbooster=True` for method `get_best_booster()`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: LightGBMTunerCV requires `return_cvbooster=True` for method `get_best_booster()`."
     ]
    }
   ],
   "source": [
    "\n",
    "train_data = lgb.Dataset(x, label=y)\n",
    "\n",
    "param = {\n",
    "    'device_type': 'gpu',\n",
    "    'objective': 'binary',\n",
    "    'boosting': 'gbdt',\n",
    "    \"verbosity\": -1,\n",
    "    # 'metric': 'kullback_leibler',\n",
    "    'metric': 'binary_logloss',\n",
    "    # 'is_unbalance': True,\n",
    "}\n",
    "tuner = optuna_lgb.LightGBMTunerCV(param,\n",
    "                                   train_data,\n",
    "                                   stratified=False,\n",
    "                                   verbose_eval=100,\n",
    "                                   early_stopping_rounds=100,\n",
    "                                   folds=KFold(n_splits=3))\n",
    "tuner.run()\n",
    "bst = tuner.get_best_booster()\n",
    "bst.save_model('model.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "agg's binary_logloss: 0.00472714 + 0.00471799\n",
      "num_leaves, val_score: 0.003120:  80%|########  | 16/20 [03:45<01:02, 15.56s/it]\u001b[32m[I 2021-01-22 16:23:50,405]\u001b[0m Trial 22 finished with value: 0.0032526158445406114 and parameters: {'num_leaves': 254}. Best is trial 19 with value: 0.003119525166714879.\u001b[0m\n",
      "num_leaves, val_score: 0.003120:  80%|########  | 16/20 [03:45<01:02, 15.56s/it][100]\tcv_agg's binary_logloss: 0.00478956 + 0.00469137\n",
      "num_leaves, val_score: 0.003120:  85%|########5 | 17/20 [04:01<00:46, 15.66s/it]\u001b[32m[I 2021-01-22 16:24:06,334]\u001b[0m Trial 23 finished with value: 0.003265801380619966 and parameters: {'num_leaves': 215}. Best is trial 19 with value: 0.003119525166714879.\u001b[0m\n",
      "num_leaves, val_score: 0.003120:  85%|########5 | 17/20 [04:01<00:46, 15.66s/it][100]\tcv_agg's binary_logloss: 0.00569347 + 0.00387411\n",
      "num_leaves, val_score: 0.003120:  90%|######### | 18/20 [04:17<00:31, 15.71s/it]\u001b[32m[I 2021-01-22 16:24:22,155]\u001b[0m Trial 24 finished with value: 0.003380813329914438 and parameters: {'num_leaves': 156}. Best is trial 19 with value: 0.003119525166714879.\u001b[0m\n",
      "num_leaves, val_score: 0.003120:  90%|######### | 18/20 [04:17<00:31, 15.71s/it][100]\tcv_agg's binary_logloss: 0.00380894 + 0.00520319\n",
      "num_leaves, val_score: 0.003120:  95%|#########5| 19/20 [04:35<00:16, 16.31s/it]\u001b[32m[I 2021-01-22 16:24:39,839]\u001b[0m Trial 25 finished with value: 0.00315027073117863 and parameters: {'num_leaves': 254}. Best is trial 19 with value: 0.003119525166714879.\u001b[0m\n",
      "num_leaves, val_score: 0.003120:  95%|#########5| 19/20 [04:35<00:16, 16.31s/it][100]\tcv_agg's binary_logloss: 0.00374503 + 0.00526478\n",
      "num_leaves, val_score: 0.003066: 100%|##########| 20/20 [04:51<00:00, 16.27s/it]\u001b[32m[I 2021-01-22 16:24:55,906]\u001b[0m Trial 26 finished with value: 0.003066422168239689 and parameters: {'num_leaves': 207}. Best is trial 26 with value: 0.003066422168239689.\u001b[0m\n",
      "num_leaves, val_score: 0.003066: 100%|##########| 20/20 [04:51<00:00, 14.56s/it]\n",
      "bagging, val_score: 0.003066:   0%|          | 0/10 [00:00<?, ?it/s][100]\tcv_agg's binary_logloss: 0.00374431 + 0.00525236\n",
      "bagging, val_score: 0.003066:  10%|#         | 1/10 [00:12<01:51, 12.35s/it]\u001b[32m[I 2021-01-22 16:25:08,444]\u001b[0m Trial 27 finished with value: 0.003083167508734294 and parameters: {'bagging_fraction': 0.6817813316918466, 'bagging_freq': 3}. Best is trial 27 with value: 0.003083167508734294.\u001b[0m\n",
      "bagging, val_score: 0.003066:  10%|#         | 1/10 [00:12<01:51, 12.35s/it][100]\tcv_agg's binary_logloss: 0.00374156 + 0.0052522\n",
      "bagging, val_score: 0.003066:  20%|##        | 2/10 [00:25<01:43, 12.96s/it]\u001b[32m[I 2021-01-22 16:25:21,821]\u001b[0m Trial 28 finished with value: 0.0030702913341979503 and parameters: {'bagging_fraction': 0.8134574106682604, 'bagging_freq': 4}. Best is trial 28 with value: 0.0030702913341979503.\u001b[0m\n",
      "bagging, val_score: 0.003066:  20%|##        | 2/10 [00:25<01:43, 12.96s/it][100]\tcv_agg's binary_logloss: 0.00373778 + 0.00525036\n",
      "bagging, val_score: 0.003066:  30%|###       | 3/10 [00:32<01:11, 10.19s/it]\u001b[32m[I 2021-01-22 16:25:28,718]\u001b[0m Trial 29 finished with value: 0.0030688389675435804 and parameters: {'bagging_fraction': 0.42230723610880333, 'bagging_freq': 3}. Best is trial 29 with value: 0.0030688389675435804.\u001b[0m\n",
      "bagging, val_score: 0.003066:  30%|###       | 3/10 [00:32<01:11, 10.19s/it][100]\tcv_agg's binary_logloss: 0.00486322 + 0.00446668\n",
      "bagging, val_score: 0.003066:  40%|####      | 4/10 [00:48<01:13, 12.30s/it]\u001b[32m[I 2021-01-22 16:25:44,264]\u001b[0m Trial 30 finished with value: 0.0032177121056601887 and parameters: {'bagging_fraction': 0.97508190722149, 'bagging_freq': 6}. Best is trial 29 with value: 0.0030688389675435804.\u001b[0m\n",
      "bagging, val_score: 0.003066:  40%|####      | 4/10 [00:48<01:13, 12.30s/it][100]\tcv_agg's binary_logloss: 0.00374711 + 0.00524828\n",
      "bagging, val_score: 0.003066:  50%|#####     | 5/10 [01:01<01:03, 12.77s/it]\u001b[32m[I 2021-01-22 16:25:57,871]\u001b[0m Trial 31 finished with value: 0.003087364200967164 and parameters: {'bagging_fraction': 0.8355002062070745, 'bagging_freq': 7}. Best is trial 29 with value: 0.0030688389675435804.\u001b[0m\n",
      "bagging, val_score: 0.003066:  50%|#####     | 5/10 [01:01<01:03, 12.77s/it][100]\tcv_agg's binary_logloss: 0.00449137 + 0.00480737\n",
      "bagging, val_score: 0.003066:  60%|######    | 6/10 [01:17<00:55, 13.80s/it]\u001b[32m[I 2021-01-22 16:26:13,706]\u001b[0m Trial 32 finished with value: 0.0031649201705781526 and parameters: {'bagging_fraction': 0.9817528591617889, 'bagging_freq': 6}. Best is trial 29 with value: 0.0030688389675435804.\u001b[0m\n",
      "bagging, val_score: 0.003066:  60%|######    | 6/10 [01:17<00:55, 13.80s/it][100]\tcv_agg's binary_logloss: 0.00374825 + 0.00525011\n",
      "bagging, val_score: 0.003066:  70%|#######   | 7/10 [01:24<00:34, 11.61s/it]\u001b[32m[I 2021-01-22 16:26:20,762]\u001b[0m Trial 33 finished with value: 0.0031076949240978467 and parameters: {'bagging_fraction': 0.44023003081025736, 'bagging_freq': 6}. Best is trial 29 with value: 0.0030688389675435804.\u001b[0m\n",
      "bagging, val_score: 0.003066:  70%|#######   | 7/10 [01:24<00:34, 11.61s/it][100]\tcv_agg's binary_logloss: 0.00374028 + 0.00525363\n",
      "bagging, val_score: 0.003061:  80%|########  | 8/10 [01:35<00:22, 11.32s/it]\u001b[32m[I 2021-01-22 16:26:31,379]\u001b[0m Trial 34 finished with value: 0.0030605131086729963 and parameters: {'bagging_fraction': 0.6489531355569791, 'bagging_freq': 4}. Best is trial 34 with value: 0.0030605131086729963.\u001b[0m\n",
      "bagging, val_score: 0.003061:  80%|########  | 8/10 [01:35<00:22, 11.32s/it][100]\tcv_agg's binary_logloss: 0.00375424 + 0.00523596\n",
      "bagging, val_score: 0.003061:  90%|######### | 9/10 [01:50<00:12, 12.48s/it]\u001b[32m[I 2021-01-22 16:26:46,528]\u001b[0m Trial 35 finished with value: 0.003072353883155778 and parameters: {'bagging_fraction': 0.9710446684923987, 'bagging_freq': 3}. Best is trial 34 with value: 0.0030605131086729963.\u001b[0m\n",
      "bagging, val_score: 0.003061:  90%|######### | 9/10 [01:50<00:12, 12.48s/it][100]\tcv_agg's binary_logloss: 0.00373405 + 0.00524145\n",
      "bagging, val_score: 0.003061: 100%|##########| 10/10 [02:00<00:00, 11.67s/it]\u001b[32m[I 2021-01-22 16:26:56,373]\u001b[0m Trial 36 finished with value: 0.003063432559164898 and parameters: {'bagging_fraction': 0.6213206557875193, 'bagging_freq': 5}. Best is trial 34 with value: 0.0030605131086729963.\u001b[0m\n",
      "bagging, val_score: 0.003061: 100%|##########| 10/10 [02:00<00:00, 12.04s/it]\n",
      "feature_fraction_stage2, val_score: 0.003061:   0%|          | 0/3 [00:00<?, ?it/s][100]\tcv_agg's binary_logloss: 0.00367067 + 0.00512584\n",
      "feature_fraction_stage2, val_score: 0.003061:  33%|###3      | 1/3 [00:07<00:15,  7.78s/it]\u001b[32m[I 2021-01-22 16:27:04,341]\u001b[0m Trial 37 finished with value: 0.00316629829328546 and parameters: {'feature_fraction': 0.92}. Best is trial 37 with value: 0.00316629829328546.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.003061:  33%|###3      | 1/3 [00:07<00:15,  7.78s/it][100]\tcv_agg's binary_logloss: 0.00372961 + 0.00523598\n",
      "feature_fraction_stage2, val_score: 0.003061:  67%|######6   | 2/3 [00:18<00:09,  9.22s/it]\u001b[32m[I 2021-01-22 16:27:14,574]\u001b[0m Trial 38 finished with value: 0.003074650644875577 and parameters: {'feature_fraction': 0.9840000000000001}. Best is trial 38 with value: 0.003074650644875577.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.003061:  67%|######6   | 2/3 [00:18<00:09,  9.22s/it][100]\tcv_agg's binary_logloss: 0.003734 + 0.0052359\n",
      "feature_fraction_stage2, val_score: 0.003061: 100%|##########| 3/3 [00:27<00:00,  9.21s/it]\u001b[32m[I 2021-01-22 16:27:23,760]\u001b[0m Trial 39 finished with value: 0.003102087641831173 and parameters: {'feature_fraction': 0.9520000000000001}. Best is trial 38 with value: 0.003074650644875577.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.003061: 100%|##########| 3/3 [00:27<00:00,  9.10s/it]\n",
      "regularization_factors, val_score: 0.003061:   0%|          | 0/20 [00:00<?, ?it/s][100]\tcv_agg's binary_logloss: 0.00328891 + 0.00400404\n",
      "regularization_factors, val_score: 0.003061:   5%|5         | 1/20 [00:02<00:45,  2.39s/it]\u001b[32m[I 2021-01-22 16:27:26,244]\u001b[0m Trial 40 finished with value: 0.003276487409190948 and parameters: {'lambda_l1': 1.8713939985609041e-07, 'lambda_l2': 0.3063001704768342}. Best is trial 40 with value: 0.003276487409190948.\u001b[0m\n",
      "regularization_factors, val_score: 0.003061:   5%|5         | 1/20 [00:02<00:45,  2.39s/it][100]\tcv_agg's binary_logloss: 0.00374246 + 0.00525795\n",
      "regularization_factors, val_score: 0.003061:  10%|#         | 2/20 [00:04<00:37,  2.06s/it]\u001b[32m[I 2021-01-22 16:27:28,068]\u001b[0m Trial 41 finished with value: 0.0030707240654798493 and parameters: {'lambda_l1': 3.5388197368265413e-08, 'lambda_l2': 8.703344486878043e-08}. Best is trial 41 with value: 0.0030707240654798493.\u001b[0m\n",
      "regularization_factors, val_score: 0.003061:  10%|#         | 2/20 [00:04<00:37,  2.06s/it][100]\tcv_agg's binary_logloss: 0.00356624 + 0.00494803\n",
      "regularization_factors, val_score: 0.003061:  15%|#5        | 3/20 [00:05<00:32,  1.91s/it]\u001b[32m[I 2021-01-22 16:27:29,799]\u001b[0m Trial 42 finished with value: 0.0030909638771758137 and parameters: {'lambda_l1': 6.03743818971583e-07, 'lambda_l2': 0.01271536420296431}. Best is trial 41 with value: 0.0030707240654798493.\u001b[0m\n",
      "regularization_factors, val_score: 0.003061:  15%|#5        | 3/20 [00:06<00:32,  1.91s/it][100]\tcv_agg's binary_logloss: 0.00377998 + 0.00520656\n",
      "regularization_factors, val_score: 0.003061:  20%|##        | 4/20 [00:07<00:29,  1.86s/it]\u001b[32m[I 2021-01-22 16:27:31,591]\u001b[0m Trial 43 finished with value: 0.0030846615673397865 and parameters: {'lambda_l1': 6.255527166114727e-06, 'lambda_l2': 8.852898832633575e-05}. Best is trial 41 with value: 0.0030707240654798493.\u001b[0m\n",
      "regularization_factors, val_score: 0.003061:  20%|##        | 4/20 [00:07<00:29,  1.86s/it][100]\tcv_agg's binary_logloss: 0.00373861 + 0.00524837\n",
      "regularization_factors, val_score: 0.003061:  25%|##5       | 5/20 [00:09<00:27,  1.85s/it]\u001b[32m[I 2021-01-22 16:27:33,420]\u001b[0m Trial 44 finished with value: 0.003071339094666404 and parameters: {'lambda_l1': 1.9993321291955087e-05, 'lambda_l2': 8.395235328898643e-06}. Best is trial 41 with value: 0.0030707240654798493.\u001b[0m\n",
      "regularization_factors, val_score: 0.003061:  25%|##5       | 5/20 [00:09<00:27,  1.85s/it][100]\tcv_agg's binary_logloss: 0.00372974 + 0.00523088\n",
      "regularization_factors, val_score: 0.003061:  30%|###       | 6/20 [00:10<00:23,  1.67s/it]\u001b[32m[I 2021-01-22 16:27:34,736]\u001b[0m Trial 45 finished with value: 0.0030791009533657865 and parameters: {'lambda_l1': 0.0007173715942994982, 'lambda_l2': 2.08662497076224e-07}. Best is trial 41 with value: 0.0030707240654798493.\u001b[0m\n",
      "regularization_factors, val_score: 0.003061:  30%|###       | 6/20 [00:10<00:23,  1.67s/it][100]\tcv_agg's binary_logloss: 0.00335277 + 0.00451142\n",
      "regularization_factors, val_score: 0.003061:  35%|###5      | 7/20 [00:12<00:21,  1.69s/it]\u001b[32m[I 2021-01-22 16:27:36,458]\u001b[0m Trial 46 finished with value: 0.0031476054754215528 and parameters: {'lambda_l1': 0.01955388084037047, 'lambda_l2': 0.029740246613662518}. Best is trial 41 with value: 0.0030707240654798493.\u001b[0m\n",
      "regularization_factors, val_score: 0.003061:  35%|###5      | 7/20 [00:12<00:21,  1.69s/it][100]\tcv_agg's binary_logloss: 0.00420607 + 0.00294259\n",
      "[200]\tcv_agg's binary_logloss: 0.00359118 + 0.00367785\n",
      "[300]\tcv_agg's binary_logloss: 0.00354504 + 0.00403509\n",
      "regularization_factors, val_score: 0.003061:  40%|####      | 8/20 [00:17<00:33,  2.79s/it]\u001b[32m[I 2021-01-22 16:27:41,600]\u001b[0m Trial 47 finished with value: 0.003515071360347013 and parameters: {'lambda_l1': 1.1813844325780188e-06, 'lambda_l2': 2.1915359970266306}. Best is trial 41 with value: 0.0030707240654798493.\u001b[0m\n",
      "[400]\tcv_agg's binary_logloss: 0.00355061 + 0.00427969\n",
      "regularization_factors, val_score: 0.003061:  40%|####      | 8/20 [00:17<00:33,  2.79s/it][100]\tcv_agg's binary_logloss: 0.00320712 + 0.00408125\n",
      "regularization_factors, val_score: 0.003061:  45%|####5     | 9/20 [00:19<00:26,  2.39s/it]\u001b[32m[I 2021-01-22 16:27:43,130]\u001b[0m Trial 48 finished with value: 0.0031710422619328424 and parameters: {'lambda_l1': 0.07852899987194033, 'lambda_l2': 0.0006852202306624704}. Best is trial 41 with value: 0.0030707240654798493.\u001b[0m\n",
      "regularization_factors, val_score: 0.003061:  45%|####5     | 9/20 [00:19<00:26,  2.39s/it][100]\tcv_agg's binary_logloss: 0.0032482 + 0.0042106\n",
      "regularization_factors, val_score: 0.003061:  50%|#####     | 10/20 [00:20<00:20,  2.05s/it]\u001b[32m[I 2021-01-22 16:27:44,404]\u001b[0m Trial 49 finished with value: 0.003125853419526105 and parameters: {'lambda_l1': 0.060810484771602516, 'lambda_l2': 1.6652956838114563e-08}. Best is trial 41 with value: 0.0030707240654798493.\u001b[0m\n",
      "regularization_factors, val_score: 0.003061:  50%|#####     | 10/20 [00:20<00:20,  2.05s/it][100]\tcv_agg's binary_logloss: 0.00374335 + 0.00525146\n",
      "regularization_factors, val_score: 0.003061:  55%|#####5    | 11/20 [00:22<00:18,  2.01s/it]\u001b[32m[I 2021-01-22 16:27:46,324]\u001b[0m Trial 50 finished with value: 0.0030780445349915414 and parameters: {'lambda_l1': 1.0096938137316739e-08, 'lambda_l2': 1.1957274031218212e-08}. Best is trial 41 with value: 0.0030707240654798493.\u001b[0m\n",
      "regularization_factors, val_score: 0.003061:  55%|#####5    | 11/20 [00:22<00:18,  2.01s/it][100]\tcv_agg's binary_logloss: 0.0037357 + 0.00524811\n",
      "regularization_factors, val_score: 0.003061:  60%|######    | 12/20 [00:24<00:14,  1.87s/it]\u001b[32m[I 2021-01-22 16:27:47,879]\u001b[0m Trial 51 finished with value: 0.0030686241389255545 and parameters: {'lambda_l1': 0.00012489639682746587, 'lambda_l2': 2.975491860797862e-06}. Best is trial 51 with value: 0.0030686241389255545.\u001b[0m\n",
      "regularization_factors, val_score: 0.003061:  60%|######    | 12/20 [00:24<00:14,  1.87s/it][100]\tcv_agg's binary_logloss: 0.00372907 + 0.00523002\n",
      "regularization_factors, val_score: 0.003061:  65%|######5   | 13/20 [00:25<00:11,  1.71s/it]\u001b[32m[I 2021-01-22 16:27:49,218]\u001b[0m Trial 52 finished with value: 0.0030610747085824917 and parameters: {'lambda_l1': 0.0006576998968851916, 'lambda_l2': 4.674775161127275e-07}. Best is trial 52 with value: 0.0030610747085824917.\u001b[0m\n",
      "regularization_factors, val_score: 0.003061:  65%|######5   | 13/20 [00:25<00:11,  1.71s/it][100]\tcv_agg's binary_logloss: 0.0037344 + 0.00523146\n",
      "regularization_factors, val_score: 0.003061:  70%|#######   | 14/20 [00:27<00:10,  1.70s/it]\u001b[32m[I 2021-01-22 16:27:50,971]\u001b[0m Trial 53 finished with value: 0.0030726772183774947 and parameters: {'lambda_l1': 0.0004416917777383857, 'lambda_l2': 1.473956952851952e-06}. Best is trial 52 with value: 0.0030610747085824917.\u001b[0m\n",
      "regularization_factors, val_score: 0.003061:  70%|#######   | 14/20 [00:27<00:10,  1.70s/it][100]\tcv_agg's binary_logloss: 0.00912207 + 0.00221378\n",
      "[200]\tcv_agg's binary_logloss: 0.00884114 + 0.00226544\n",
      "[300]\tcv_agg's binary_logloss: 0.00878322 + 0.00227731\n",
      "[400]\tcv_agg's binary_logloss: 0.00872338 + 0.00227159\n",
      "[500]\tcv_agg's binary_logloss: 0.00872071 + 0.00226782\n",
      "[600]\tcv_agg's binary_logloss: 0.00871904 + 0.00226545\n",
      "regularization_factors, val_score: 0.003061:  75%|#######5  | 15/20 [00:29<00:09,  1.81s/it]\u001b[32m[I 2021-01-22 16:27:52,955]\u001b[0m Trial 54 finished with value: 0.008719035235168926 and parameters: {'lambda_l1': 2.6863953630645185, 'lambda_l2': 7.253303361622005e-06}. Best is trial 52 with value: 0.0030610747085824917.\u001b[0m\n",
      "regularization_factors, val_score: 0.003061:  75%|#######5  | 15/20 [00:29<00:09,  1.81s/it][100]\tcv_agg's binary_logloss: 0.00366852 + 0.00511835\n",
      "regularization_factors, val_score: 0.003061:  80%|########  | 16/20 [00:30<00:06,  1.65s/it]\u001b[32m[I 2021-01-22 16:27:54,290]\u001b[0m Trial 55 finished with value: 0.003095830648727149 and parameters: {'lambda_l1': 0.0036109378763080013, 'lambda_l2': 6.137225360909159e-07}. Best is trial 52 with value: 0.0030610747085824917.\u001b[0m\n",
      "regularization_factors, val_score: 0.003061:  80%|########  | 16/20 [00:30<00:06,  1.65s/it][100]\tcv_agg's binary_logloss: 0.00374145 + 0.00524667\n",
      "regularization_factors, val_score: 0.003061:  85%|########5 | 17/20 [00:32<00:05,  1.67s/it]\u001b[32m[I 2021-01-22 16:27:55,973]\u001b[0m Trial 56 finished with value: 0.003068487651288082 and parameters: {'lambda_l1': 1.3763310110643187e-05, 'lambda_l2': 0.00013380781349789877}. Best is trial 52 with value: 0.0030610747085824917.\u001b[0m\n",
      "regularization_factors, val_score: 0.003061:  85%|########5 | 17/20 [00:32<00:05,  1.67s/it][100]\tcv_agg's binary_logloss: 0.00373628 + 0.00524519\n",
      "regularization_factors, val_score: 0.003061:  90%|######### | 18/20 [00:33<00:03,  1.66s/it]\u001b[32m[I 2021-01-22 16:27:57,587]\u001b[0m Trial 57 finished with value: 0.0030801164390411684 and parameters: {'lambda_l1': 2.485921340755883e-05, 'lambda_l2': 0.00020107725158190968}. Best is trial 52 with value: 0.0030610747085824917.\u001b[0m\n",
      "regularization_factors, val_score: 0.003061:  90%|######### | 18/20 [00:33<00:03,  1.66s/it][100]\tcv_agg's binary_logloss: 0.0053595 + 0.00277965\n",
      "[200]\tcv_agg's binary_logloss: 0.00526152 + 0.00278648\n",
      "[300]\tcv_agg's binary_logloss: 0.00524794 + 0.00276728\n",
      "[400]\tcv_agg's binary_logloss: 0.00524361 + 0.00276115\n",
      "regularization_factors, val_score: 0.003061:  95%|#########5| 19/20 [00:35<00:01,  1.78s/it][500]\tcv_agg's binary_logloss: 0.00524351 + 0.00276102\n",
      "\u001b[32m[I 2021-01-22 16:27:59,652]\u001b[0m Trial 58 finished with value: 0.005243508805861933 and parameters: {'lambda_l1': 1.2007679368383535, 'lambda_l2': 0.001086708261044102}. Best is trial 52 with value: 0.0030610747085824917.\u001b[0m\n",
      "regularization_factors, val_score: 0.003061:  95%|#########5| 19/20 [00:35<00:01,  1.78s/it][100]\tcv_agg's binary_logloss: 0.00364068 + 0.0050833\n",
      "regularization_factors, val_score: 0.003061: 100%|##########| 20/20 [00:37<00:00,  1.70s/it]\u001b[32m[I 2021-01-22 16:28:01,158]\u001b[0m Trial 59 finished with value: 0.003089832374243228 and parameters: {'lambda_l1': 0.004578757730738266, 'lambda_l2': 3.23025050024125e-05}. Best is trial 52 with value: 0.0030610747085824917.\u001b[0m\n",
      "regularization_factors, val_score: 0.003061: 100%|##########| 20/20 [00:37<00:00,  1.87s/it]\n",
      "min_data_in_leaf, val_score: 0.003061:   0%|          | 0/5 [00:00<?, ?it/s][100]\tcv_agg's binary_logloss: 0.00374069 + 0.00525545\n",
      "min_data_in_leaf, val_score: 0.003061:  20%|##        | 1/5 [00:08<00:34,  8.56s/it]\u001b[32m[I 2021-01-22 16:28:09,856]\u001b[0m Trial 60 finished with value: 0.003074667011652699 and parameters: {'min_child_samples': 25}. Best is trial 60 with value: 0.003074667011652699.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.003061:  20%|##        | 1/5 [00:08<00:34,  8.56s/it][100]\tcv_agg's binary_logloss: 0.00373972 + 0.00525248\n",
      "min_data_in_leaf, val_score: 0.003061:  40%|####      | 2/5 [00:40<01:07, 22.37s/it]\u001b[32m[I 2021-01-22 16:28:41,851]\u001b[0m Trial 61 finished with value: 0.0030850683119596784 and parameters: {'min_child_samples': 5}. Best is trial 60 with value: 0.003074667011652699.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.003061:  40%|####      | 2/5 [00:40<01:07, 22.37s/it][100]\tcv_agg's binary_logloss: 0.00375256 + 0.00525241\n",
      "min_data_in_leaf, val_score: 0.003061:  60%|######    | 3/5 [00:42<00:26, 13.22s/it]\u001b[32m[I 2021-01-22 16:28:44,194]\u001b[0m Trial 62 finished with value: 0.00312150882770451 and parameters: {'min_child_samples': 100}. Best is trial 60 with value: 0.003074667011652699.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.003061:  60%|######    | 3/5 [00:43<00:26, 13.22s/it][100]\tcv_agg's binary_logloss: 0.00383072 + 0.00519299\n",
      "min_data_in_leaf, val_score: 0.003061:  80%|########  | 4/5 [01:02<00:15, 15.64s/it]\u001b[32m[I 2021-01-22 16:29:03,530]\u001b[0m Trial 63 finished with value: 0.0032806598641967294 and parameters: {'min_child_samples': 10}. Best is trial 60 with value: 0.003074667011652699.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.003061:  80%|########  | 4/5 [01:02<00:15, 15.64s/it][100]\tcv_agg's binary_logloss: 0.00374573 + 0.00525191\n",
      "min_data_in_leaf, val_score: 0.003061: 100%|##########| 5/5 [01:06<00:00, 11.66s/it]\u001b[32m[I 2021-01-22 16:29:08,146]\u001b[0m Trial 64 finished with value: 0.003090488525257746 and parameters: {'min_child_samples': 50}. Best is trial 60 with value: 0.003074667011652699.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.003061: 100%|##########| 5/5 [01:06<00:00, 13.40s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<lightgbm.basic.Booster at 0x7fd496691850>,\n",
       " <lightgbm.basic.Booster at 0x7fd496691fd0>,\n",
       " <lightgbm.basic.Booster at 0x7fd4966911f0>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_data = lgb.Dataset(x, label=y)\n",
    "\n",
    "param = {\n",
    "    'device_type': 'gpu',\n",
    "    'objective': 'binary',\n",
    "    'boosting': 'gbdt',\n",
    "    \"verbosity\": -1,\n",
    "    # 'metric': 'kullback_leibler',\n",
    "    'metric': 'binary_logloss',\n",
    "    # 'is_unbalance': True,\n",
    "}\n",
    "tuner = optuna_lgb.LightGBMTunerCV(param,\n",
    "                                   train_data,\n",
    "                                   stratified=False,\n",
    "                                   verbose_eval=100,\n",
    "                                   early_stopping_rounds=100,\n",
    "                                   return_cvbooster=True,\n",
    "                                   folds=KFold(n_splits=3, shuffle=True))\n",
    "tuner.run()\n",
    "bst = tuner.get_best_booster()\n",
    "bst.save_model('model.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0, 0.0, 0.0, 0.0, 0.0, 6, 22, 8, 1.0799589994281866], [0.0, 0.0, 0.0, 0.0, 0.0, 6, 5, 1, 2.718281828459045], [0.0, 0.0, 0.0, 0.0, 0.0, 6, 4, 4, 1.2840254166877414], [0.0, 0.0, 0.0, 0.0, 0.0, 6, 4, 4, 1.2840254166877414], [0.0, 0.0, 0.0, 0.0, 0.0, 6, 3, 3, 1.3956124250860895], [0.0, 0.0, 0.0, 0.0, 0.0, 6, 1, 1, 2.718281828459045], [0.0, 0.0, 0.0, 0.0, 0.0, 6, 7, 6, 1.1535649948951077], [0.0, 0.0, 0.0, 0.0, 0.0, 6, 6, 2, 1.1813604128656459], [0.0, 0.0, 0.0, 0.0, 0.0, 6, 24, 2, 1.0425469051899914], [0.0, 0.0, 0.0, 0.0, 0.0, 6, 59, 1, 2.718281828459045], [0.0, 0.0, 0.0, 0.0, 0.0, 6, 6, 2, 1.1813604128656459], [0.0, 0.0, 0.0, 0.0, 0.0, 6, 42, 9, 1.0281671774377144]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/trainer/train.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m                            \u001b[0;34m'messageUniqueness'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bwtrl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                        ])\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0membeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0memb_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'emb_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0memb_columns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "msg = [\n",
    "    'HEEERRREESSS SUISEI~~~', 'wwwww', 'なにそれ', 'YABE', 'やばい', '草', 'lol why',\n",
    "    'クソクソクソ', '死ね死ね死ね死ね死ね死ね死ね死ね死ね死ね死ね死ね',\n",
    "    'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa', 'きもきもきも',\n",
    "    'パピオン加藤最強!!パピオン加藤最強!!!パピオン加藤最強!!パピオン加藤最強!!!'\n",
    "]\n",
    "bwt = np.nan\n",
    "test_data = [[\n",
    "    0.0, 0.0, 0.0, 0.0, 0.0, 6,\n",
    "    len(x),\n",
    "    len(set(x)),\n",
    "    balanced_bwt_rl_entropy([x])\n",
    "] for x in msg]\n",
    "print(test_data)\n",
    "test_df = pd.DataFrame(test_data,\n",
    "                       columns=[\n",
    "                           'isVerified', 'isOwner', 'isModerator', 'isMember',\n",
    "                           'isSuperchat', 'authorLength', 'messageLength',\n",
    "                           'messageUniqueness', 'bwtrl'\n",
    "                       ])\n",
    "embeds = model.encode(msg)\n",
    "emb_columns = ['emb_' + str(i) for i in range(embeds.shape[1])]\n",
    "test_df[emb_columns] = embeds\n",
    "test_df['isMember'] = test_df['isMember']\n",
    "test_df['isSuperchat'] = test_df['isSuperchat']\n",
    "sam = data[data['spam'] == 1.0].sample(10)\n",
    "val_pred = bst.predict(test_df)\n",
    "print(val_pred)\n",
    "print((val_pred > 0.65).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('paraphrase-xlm-r-multilingual-v1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0, 0.0, 0.0, 0.0, 0.0, 6, 22, 8, 1.0799589994281866], [0.0, 0.0, 0.0, 0.0, 0.0, 6, 5, 1, 2.718281828459045], [0.0, 0.0, 0.0, 0.0, 0.0, 6, 4, 4, 1.2840254166877414], [0.0, 0.0, 0.0, 0.0, 0.0, 6, 4, 4, 1.2840254166877414], [0.0, 0.0, 0.0, 0.0, 0.0, 6, 3, 3, 1.3956124250860895], [0.0, 0.0, 0.0, 0.0, 0.0, 6, 1, 1, 2.718281828459045], [0.0, 0.0, 0.0, 0.0, 0.0, 6, 7, 6, 1.1535649948951077], [0.0, 0.0, 0.0, 0.0, 0.0, 6, 6, 2, 1.1813604128656459], [0.0, 0.0, 0.0, 0.0, 0.0, 6, 24, 2, 1.0425469051899914], [0.0, 0.0, 0.0, 0.0, 0.0, 6, 59, 1, 2.718281828459045], [0.0, 0.0, 0.0, 0.0, 0.0, 6, 6, 2, 1.1813604128656459], [0.0, 0.0, 0.0, 0.0, 0.0, 6, 42, 9, 1.0281671774377144]]\n",
      "[array([0.99999873, 0.99999723, 0.99999722, 0.99999722, 0.99999644,\n",
      "       0.99999658, 0.99999685, 0.99999707, 0.99999854, 0.99999928,\n",
      "       0.99999711, 0.99999919]), array([0.99999676, 0.99999669, 0.99999816, 0.9999974 , 0.99999763,\n",
      "       0.99999799, 0.99999771, 0.99999719, 0.99999854, 0.99999928,\n",
      "       0.99999734, 0.9999986 ]), array([0.99999826, 0.99999711, 0.99999747, 0.99999639, 0.99999761,\n",
      "       0.99999744, 0.99999692, 0.99999784, 0.99999941, 0.99999972,\n",
      "       0.99999753, 0.99999906])]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'list' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/trainer/train.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mval_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_pred\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.65\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'list' and 'float'"
     ]
    }
   ],
   "source": [
    "msg = [\n",
    "    'HEEERRREESSS SUISEI~~~', 'wwwww', 'なにそれ', 'YABE', 'やばい', '草', 'lol why',\n",
    "    'クソクソクソ', '死ね死ね死ね死ね死ね死ね死ね死ね死ね死ね死ね死ね',\n",
    "    'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa', 'きもきもきも',\n",
    "    'パピオン加藤最強!!パピオン加藤最強!!!パピオン加藤最強!!パピオン加藤最強!!!'\n",
    "]\n",
    "bwt = np.nan\n",
    "test_data = [[\n",
    "    0.0, 0.0, 0.0, 0.0, 0.0, 6,\n",
    "    len(x),\n",
    "    len(set(x)),\n",
    "    balanced_bwt_rl_entropy([x])\n",
    "] for x in msg]\n",
    "print(test_data)\n",
    "test_df = pd.DataFrame(test_data,\n",
    "                       columns=[\n",
    "                           'isVerified', 'isOwner', 'isModerator', 'isMember',\n",
    "                           'isSuperchat', 'authorLength', 'messageLength',\n",
    "                           'messageUniqueness', 'bwtrl'\n",
    "                       ])\n",
    "embeds = model.encode(msg)\n",
    "emb_columns = ['emb_' + str(i) for i in range(embeds.shape[1])]\n",
    "test_df[emb_columns] = embeds\n",
    "test_df['isMember'] = test_df['isMember']\n",
    "test_df['isSuperchat'] = test_df['isSuperchat']\n",
    "sam = data[data['spam'] == 1.0].sample(10)\n",
    "val_pred = bst.predict(test_df)\n",
    "print(val_pred)\n",
    "print((val_pred > 0.65).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s trial 10 with value: 1.0.\u001b[0m\n",
      "num_leaves, val_score: 1.000000:  65%|######5   | 13/20 [01:54<01:06,  9.55s/it][100]\tcv_agg's auc: 0.999505 + 0.000699488\n",
      "num_leaves, val_score: 1.000000:  70%|#######   | 14/20 [02:04<00:58,  9.82s/it]\u001b[32m[I 2021-01-22 16:34:14,917]\u001b[0m Trial 20 finished with value: 0.9998548236529409 and parameters: {'num_leaves': 168}. Best is trial 10 with value: 1.0.\u001b[0m\n",
      "num_leaves, val_score: 1.000000:  70%|#######   | 14/20 [02:05<00:58,  9.82s/it][100]\tcv_agg's auc: 0.99951 + 0.00069337\n",
      "num_leaves, val_score: 1.000000:  75%|#######5  | 15/20 [02:13<00:47,  9.59s/it]\u001b[32m[I 2021-01-22 16:34:23,978]\u001b[0m Trial 21 finished with value: 0.9995764908488635 and parameters: {'num_leaves': 67}. Best is trial 10 with value: 1.0.\u001b[0m\n",
      "num_leaves, val_score: 1.000000:  80%|########  | 16/20 [02:24<00:39,  9.79s/it][100]\tcv_agg's auc: 0.999566 + 0.000613983\n",
      "\u001b[32m[I 2021-01-22 16:34:34,223]\u001b[0m Trial 22 finished with value: 0.9999983040959476 and parameters: {'num_leaves': 256}. Best is trial 10 with value: 1.0.\u001b[0m\n",
      "num_leaves, val_score: 1.000000:  80%|########  | 16/20 [02:24<00:39,  9.79s/it][100]\tcv_agg's auc: 0.999548 + 0.000638937\n",
      "num_leaves, val_score: 1.000000:  85%|########5 | 17/20 [02:34<00:30, 10.04s/it]\u001b[32m[I 2021-01-22 16:34:44,854]\u001b[0m Trial 23 finished with value: 0.9999656428227857 and parameters: {'num_leaves': 254}. Best is trial 10 with value: 1.0.\u001b[0m\n",
      "num_leaves, val_score: 1.000000:  85%|########5 | 17/20 [02:34<00:30, 10.04s/it][100]\tcv_agg's auc: 0.999491 + 0.000720511\n",
      "num_leaves, val_score: 1.000000:  90%|######### | 18/20 [02:47<00:21, 10.75s/it]\u001b[32m[I 2021-01-22 16:34:57,276]\u001b[0m Trial 24 finished with value: 0.9999676251331203 and parameters: {'num_leaves': 249}. Best is trial 10 with value: 1.0.\u001b[0m\n",
      "num_leaves, val_score: 1.000000:  90%|######### | 18/20 [02:47<00:21, 10.75s/it][100]\tcv_agg's auc: 0.999574 + 0.000601991\n",
      "num_leaves, val_score: 1.000000:  95%|#########5| 19/20 [02:57<00:10, 10.74s/it]\u001b[32m[I 2021-01-22 16:35:07,987]\u001b[0m Trial 25 finished with value: 0.9999372515500563 and parameters: {'num_leaves': 181}. Best is trial 10 with value: 1.0.\u001b[0m\n",
      "num_leaves, val_score: 1.000000:  95%|#########5| 19/20 [02:58<00:10, 10.74s/it][100]\tcv_agg's auc: 0.99955 + 0.000636508\n",
      "num_leaves, val_score: 1.000000: 100%|##########| 20/20 [03:07<00:00, 10.52s/it]\u001b[32m[I 2021-01-22 16:35:17,987]\u001b[0m Trial 26 finished with value: 0.9997371675943105 and parameters: {'num_leaves': 230}. Best is trial 10 with value: 1.0.\u001b[0m\n",
      "num_leaves, val_score: 1.000000: 100%|##########| 20/20 [03:08<00:00,  9.40s/it]\n",
      "bagging, val_score: 1.000000:   0%|          | 0/10 [00:00<?, ?it/s][100]\tcv_agg's auc: 0.999456 + 0.000769754\n",
      "bagging, val_score: 1.000000:  10%|#         | 1/10 [00:08<01:14,  8.29s/it]\u001b[32m[I 2021-01-22 16:35:26,474]\u001b[0m Trial 27 finished with value: 0.9994753754344546 and parameters: {'bagging_fraction': 0.6673819861169445, 'bagging_freq': 2}. Best is trial 27 with value: 0.9994753754344546.\u001b[0m\n",
      "bagging, val_score: 1.000000:  10%|#         | 1/10 [00:08<01:14,  8.29s/it][100]\tcv_agg's auc: 0.999563 + 0.000618318\n",
      "bagging, val_score: 1.000000:  20%|##        | 2/10 [00:16<01:05,  8.19s/it]\u001b[32m[I 2021-01-22 16:35:34,594]\u001b[0m Trial 28 finished with value: 0.999920659438235 and parameters: {'bagging_fraction': 0.8024898267554299, 'bagging_freq': 5}. Best is trial 28 with value: 0.999920659438235.\u001b[0m\n",
      "bagging, val_score: 1.000000:  20%|##        | 2/10 [00:16<01:05,  8.19s/it][100]\tcv_agg's auc: 0.999494 + 0.000715452\n",
      "bagging, val_score: 1.000000:  30%|###       | 3/10 [00:23<00:55,  7.89s/it]\u001b[32m[I 2021-01-22 16:35:42,132]\u001b[0m Trial 29 finished with value: 0.9996192701460855 and parameters: {'bagging_fraction': 0.7530227539663137, 'bagging_freq': 7}. Best is trial 28 with value: 0.999920659438235.\u001b[0m\n",
      "bagging, val_score: 1.000000:  30%|###       | 3/10 [00:24<00:55,  7.89s/it][100]\tcv_agg's auc: 0.999501 + 0.000705909\n",
      "bagging, val_score: 1.000000:  40%|####      | 4/10 [00:29<00:42,  7.16s/it]\u001b[32m[I 2021-01-22 16:35:48,168]\u001b[0m Trial 30 finished with value: 0.9999777774358921 and parameters: {'bagging_fraction': 0.6148615191974921, 'bagging_freq': 5}. Best is trial 30 with value: 0.9999777774358921.\u001b[0m\n",
      "bagging, val_score: 1.000000:  40%|####      | 4/10 [00:30<00:42,  7.16s/it][100]\tcv_agg's auc: 0.999489 + 0.000722741\n",
      "bagging, val_score: 1.000000:  50%|#####     | 5/10 [00:36<00:33,  6.80s/it]\u001b[32m[I 2021-01-22 16:35:54,325]\u001b[0m Trial 31 finished with value: 0.9996352066846654 and parameters: {'bagging_fraction': 0.5497000179482582, 'bagging_freq': 1}. Best is trial 30 with value: 0.9999777774358921.\u001b[0m\n",
      "bagging, val_score: 1.000000:  60%|######    | 6/10 [00:43<00:28,  7.12s/it][100]\tcv_agg's auc: 0.999532 + 0.000661236\n",
      "\u001b[32m[I 2021-01-22 16:36:02,078]\u001b[0m Trial 32 finished with value: 0.9997836642049748 and parameters: {'bagging_fraction': 0.8099374448146474, 'bagging_freq': 6}. Best is trial 30 with value: 0.9999777774358921.\u001b[0m\n",
      "bagging, val_score: 1.000000:  60%|######    | 6/10 [00:43<00:28,  7.12s/it][100]\tcv_agg's auc: 0.99948 + 0.000735255\n",
      "bagging, val_score: 1.000000:  70%|#######   | 7/10 [00:51<00:21,  7.18s/it]\u001b[32m[I 2021-01-22 16:36:09,377]\u001b[0m Trial 33 finished with value: 0.9994853301650607 and parameters: {'bagging_fraction': 0.7480736641423686, 'bagging_freq': 4}. Best is trial 30 with value: 0.9999777774358921.\u001b[0m\n",
      "bagging, val_score: 1.000000:  80%|########  | 8/10 [00:58<00:14,  7.12s/it][100]\tcv_agg's auc: 0.999504 + 0.000701875\n",
      "\u001b[32m[I 2021-01-22 16:36:16,367]\u001b[0m Trial 34 finished with value: 0.9999459808941175 and parameters: {'bagging_fraction': 0.6962677416835248, 'bagging_freq': 3}. Best is trial 30 with value: 0.9999777774358921.\u001b[0m\n",
      "bagging, val_score: 1.000000:  80%|########  | 8/10 [00:58<00:14,  7.12s/it][100]\tcv_agg's auc: 0.999628 + 0.000525451\n",
      "bagging, val_score: 1.000000:  90%|######### | 9/10 [01:03<00:06,  6.49s/it]\u001b[32m[I 2021-01-22 16:36:21,457]\u001b[0m Trial 35 finished with value: 0.9999143894253818 and parameters: {'bagging_fraction': 0.44897806315428673, 'bagging_freq': 7}. Best is trial 30 with value: 0.9999777774358921.\u001b[0m\n",
      "bagging, val_score: 1.000000:  90%|######### | 9/10 [01:03<00:06,  6.49s/it][100]\tcv_agg's auc: 0.999495 + 0.000714205\n",
      "bagging, val_score: 1.000000: 100%|##########| 10/10 [01:11<00:00,  7.15s/it]\u001b[32m[I 2021-01-22 16:36:30,106]\u001b[0m Trial 36 finished with value: 0.9995522512391187 and parameters: {'bagging_fraction': 0.9305835986935136, 'bagging_freq': 4}. Best is trial 30 with value: 0.9999777774358921.\u001b[0m\n",
      "bagging, val_score: 1.000000: 100%|##########| 10/10 [01:12<00:00,  7.20s/it]\n",
      "feature_fraction_stage2, val_score: 1.000000:   0%|          | 0/6 [00:00<?, ?it/s][100]\tcv_agg's auc: 0.99955 + 0.000637017\n",
      "feature_fraction_stage2, val_score: 1.000000:  17%|#6        | 1/6 [00:09<00:45,  9.17s/it]\u001b[32m[I 2021-01-22 16:36:39,379]\u001b[0m Trial 37 finished with value: 0.9997869078246407 and parameters: {'feature_fraction': 0.652}. Best is trial 37 with value: 0.9997869078246407.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 1.000000:  17%|#6        | 1/6 [00:09<00:45,  9.17s/it][100]\tcv_agg's auc: 0.999581 + 0.000591897\n",
      "feature_fraction_stage2, val_score: 1.000000:  33%|###3      | 2/6 [00:19<00:38,  9.70s/it]\u001b[32m[I 2021-01-22 16:36:49,449]\u001b[0m Trial 38 finished with value: 0.999740577785157 and parameters: {'feature_fraction': 0.716}. Best is trial 37 with value: 0.9997869078246407.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 1.000000:  33%|###3      | 2/6 [00:19<00:38,  9.70s/it][100]\tcv_agg's auc: 0.999506 + 0.000698517\n",
      "feature_fraction_stage2, val_score: 1.000000:  50%|#####     | 3/6 [00:28<00:28,  9.44s/it]\u001b[32m[I 2021-01-22 16:36:58,585]\u001b[0m Trial 39 finished with value: 0.9997118763537953 and parameters: {'feature_fraction': 0.62}. Best is trial 37 with value: 0.9997869078246407.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 1.000000:  50%|#####     | 3/6 [00:28<00:28,  9.44s/it][100]\tcv_agg's auc: 0.999486 + 0.000727035\n",
      "feature_fraction_stage2, val_score: 1.000000:  67%|######6   | 4/6 [00:38<00:19,  9.60s/it]\u001b[32m[I 2021-01-22 16:37:08,430]\u001b[0m Trial 40 finished with value: 0.9996106391585761 and parameters: {'feature_fraction': 0.748}. Best is trial 37 with value: 0.9997869078246407.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 1.000000:  67%|######6   | 4/6 [00:38<00:19,  9.60s/it][100]\tcv_agg's auc: 0.999491 + 0.000719511\n",
      "feature_fraction_stage2, val_score: 1.000000:  83%|########3 | 5/6 [00:47<00:09,  9.64s/it]\u001b[32m[I 2021-01-22 16:37:18,152]\u001b[0m Trial 41 finished with value: 0.9998711112920075 and parameters: {'feature_fraction': 0.6839999999999999}. Best is trial 41 with value: 0.9998711112920075.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 1.000000:  83%|########3 | 5/6 [00:48<00:09,  9.64s/it][100]\tcv_agg's auc: 0.999611 + 0.000549964\n",
      "feature_fraction_stage2, val_score: 1.000000: 100%|##########| 6/6 [00:58<00:00,  9.80s/it]\u001b[32m[I 2021-01-22 16:37:28,252]\u001b[0m Trial 42 finished with value: 0.999704035612087 and parameters: {'feature_fraction': 0.7799999999999999}. Best is trial 41 with value: 0.9998711112920075.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 1.000000: 100%|##########| 6/6 [00:58<00:00,  9.69s/it]\n",
      "regularization_factors, val_score: 1.000000:   5%|5         | 1/20 [00:05<01:44,  5.51s/it]\u001b[32m[I 2021-01-22 16:37:33,862]\u001b[0m Trial 43 finished with value: 0.9996133751306164 and parameters: {'lambda_l1': 3.828752774042536e-07, 'lambda_l2': 2.842540873898585e-06}. Best is trial 43 with value: 0.9996133751306164.\u001b[0m\n",
      "regularization_factors, val_score: 1.000000:   5%|5         | 1/20 [00:05<01:44,  5.51s/it][100]\tcv_agg's auc: 0.999493 + 0.000716712\n",
      "regularization_factors, val_score: 1.000000:  10%|#         | 2/20 [00:06<00:51,  2.84s/it]\u001b[32m[I 2021-01-22 16:37:34,842]\u001b[0m Trial 44 finished with value: 0.9997664501806348 and parameters: {'lambda_l1': 3.9327622632114574, 'lambda_l2': 7.519562505138564e-05}. Best is trial 44 with value: 0.9997664501806348.\u001b[0m\n",
      "regularization_factors, val_score: 1.000000:  10%|#         | 2/20 [00:06<00:51,  2.84s/it][100]\tcv_agg's auc: 0.999635 + 0.000516763\n",
      "regularization_factors, val_score: 1.000000:  15%|#5        | 3/20 [00:08<00:40,  2.36s/it]\u001b[32m[I 2021-01-22 16:37:36,636]\u001b[0m Trial 45 finished with value: 0.9996932308522114 and parameters: {'lambda_l1': 0.17960039047263057, 'lambda_l2': 0.7454875540660221}. Best is trial 44 with value: 0.9997664501806348.\u001b[0m\n",
      "regularization_factors, val_score: 1.000000:  15%|#5        | 3/20 [00:08<00:40,  2.36s/it][100]\tcv_agg's auc: 0.999582 + 0.000591163\n",
      "regularization_factors, val_score: 1.000000:  20%|##        | 4/20 [00:09<00:33,  2.09s/it]\u001b[32m[I 2021-01-22 16:37:38,317]\u001b[0m Trial 46 finished with value: 0.9998518937059105 and parameters: {'lambda_l1': 0.0036266876268237296, 'lambda_l2': 7.888323998905689}. Best is trial 46 with value: 0.9998518937059105.\u001b[0m\n",
      "regularization_factors, val_score: 1.000000:  20%|##        | 4/20 [00:10<00:33,  2.09s/it][100]\tcv_agg's auc: 0.999591 + 0.000578722\n",
      "regularization_factors, val_score: 1.000000:  25%|##5       | 5/20 [00:12<00:35,  2.39s/it]\u001b[32m[I 2021-01-22 16:37:41,238]\u001b[0m Trial 47 finished with value: 0.9997578614595027 and parameters: {'lambda_l1': 0.0005006609467562651, 'lambda_l2': 0.023543076992573284}. Best is trial 46 with value: 0.9998518937059105.\u001b[0m\n",
      "regularization_factors, val_score: 1.000000:  25%|##5       | 5/20 [00:12<00:35,  2.39s/it][100]\tcv_agg's auc: 0.999543 + 0.000646557\n",
      "regularization_factors, val_score: 1.000000:  30%|###       | 6/20 [00:16<00:39,  2.85s/it]\u001b[32m[I 2021-01-22 16:37:44,961]\u001b[0m Trial 48 finished with value: 0.9996056616912918 and parameters: {'lambda_l1': 0.00010508951996921524, 'lambda_l2': 4.4766387853023316e-08}. Best is trial 46 with value: 0.9998518937059105.\u001b[0m\n",
      "regularization_factors, val_score: 1.000000:  30%|###       | 6/20 [00:16<00:39,  2.85s/it][100]\tcv_agg's auc: 0.999502 + 0.000704811\n",
      "regularization_factors, val_score: 1.000000:  35%|###5      | 7/20 [00:18<00:34,  2.66s/it]\u001b[32m[I 2021-01-22 16:37:47,252]\u001b[0m Trial 49 finished with value: 0.9998009224786961 and parameters: {'lambda_l1': 7.752648845585292e-08, 'lambda_l2': 0.3798013317277559}. Best is trial 46 with value: 0.9998518937059105.\u001b[0m\n",
      "regularization_factors, val_score: 1.000000:  35%|###5      | 7/20 [00:18<00:34,  2.66s/it][100]\tcv_agg's auc: 0.999586 + 0.000585014\n",
      "regularization_factors, val_score: 1.000000:  40%|####      | 8/20 [00:22<00:37,  3.11s/it]\u001b[32m[I 2021-01-22 16:37:51,321]\u001b[0m Trial 50 finished with value: 0.9996715043576471 and parameters: {'lambda_l1': 1.7896173457257638e-06, 'lambda_l2': 7.173073210198592e-05}. Best is trial 46 with value: 0.9998518937059105.\u001b[0m\n",
      "regularization_factors, val_score: 1.000000:  40%|####      | 8/20 [00:23<00:37,  3.11s/it][100]\tcv_agg's auc: 0.999522 + 0.000675293\n",
      "regularization_factors, val_score: 1.000000:  45%|####5     | 9/20 [00:26<00:35,  3.20s/it]\u001b[32m[I 2021-01-22 16:37:54,708]\u001b[0m Trial 51 finished with value: 0.9997002900582657 and parameters: {'lambda_l1': 0.00014742562108977666, 'lambda_l2': 0.0003059918167766949}. Best is trial 46 with value: 0.9998518937059105.\u001b[0m\n",
      "regularization_factors, val_score: 1.000000:  45%|####5     | 9/20 [00:26<00:35,  3.20s/it][100]\tcv_agg's auc: 0.99948 + 0.000735159\n",
      "regularization_factors, val_score: 1.000000:  50%|#####     | 10/20 [00:27<00:26,  2.62s/it]\u001b[32m[I 2021-01-22 16:37:56,034]\u001b[0m Trial 52 finished with value: 0.9999546261192224 and parameters: {'lambda_l1': 2.6668485217632094, 'lambda_l2': 0.0004427330543300672}. Best is trial 52 with value: 0.9999546261192224.\u001b[0m\n",
      "regularization_factors, val_score: 1.000000:  50%|#####     | 10/20 [00:27<00:26,  2.62s/it][100]\tcv_agg's auc: 0.999724 + 0.000389763\n",
      "regularization_factors, val_score: 1.000000:  55%|#####5    | 11/20 [00:28<00:18,  2.10s/it]\u001b[32m[I 2021-01-22 16:37:56,958]\u001b[0m Trial 53 finished with value: 0.9997441813888596 and parameters: {'lambda_l1': 5.563145306602492, 'lambda_l2': 0.010907785719179061}. Best is trial 52 with value: 0.9999546261192224.\u001b[0m\n",
      "regularization_factors, val_score: 1.000000:  55%|#####5    | 11/20 [00:28<00:18,  2.10s/it][100]\tcv_agg's auc: 0.999604 + 0.000559334\n",
      "[100]\tcv_agg's auc: 0.999571 + 0.000606625\n",
      "regularization_factors, val_score: 1.000000:  60%|######    | 12/20 [00:30<00:17,  2.18s/it]\u001b[32m[I 2021-01-22 16:37:59,317]\u001b[0m Trial 54 finished with value: 0.9995878071339526 and parameters: {'lambda_l1': 0.0257788965111148, 'lambda_l2': 3.745471631941738}. Best is trial 52 with value: 0.9999546261192224.\u001b[0m\n",
      "regularization_factors, val_score: 1.000000:  65%|######5   | 13/20 [00:33<00:16,  2.30s/it]\u001b[32m[I 2021-01-22 16:38:01,904]\u001b[0m Trial 55 finished with value: 0.9995745475676573 and parameters: {'lambda_l1': 0.02760323825271896, 'lambda_l2': 8.437518059849006e-08}. Best is trial 52 with value: 0.9999546261192224.\u001b[0m\n",
      "regularization_factors, val_score: 1.000000:  65%|######5   | 13/20 [00:33<00:16,  2.30s/it][100]\tcv_agg's auc: 0.999569 + 0.000609018\n",
      "regularization_factors, val_score: 1.000000:  70%|#######   | 14/20 [00:35<00:12,  2.08s/it]\u001b[32m[I 2021-01-22 16:38:03,456]\u001b[0m Trial 56 finished with value: 0.9996810675043407 and parameters: {'lambda_l1': 0.3992788334331996, 'lambda_l2': 0.012828225974432108}. Best is trial 52 with value: 0.9999546261192224.\u001b[0m\n",
      "regularization_factors, val_score: 1.000000:  70%|#######   | 14/20 [00:35<00:12,  2.08s/it][100]\tcv_agg's auc: 0.999592 + 0.000576392\n",
      "regularization_factors, val_score: 1.000000:  75%|#######5  | 15/20 [00:38<00:11,  2.38s/it]\u001b[32m[I 2021-01-22 16:38:06,520]\u001b[0m Trial 57 finished with value: 0.9996802267360744 and parameters: {'lambda_l1': 0.0027227130435329453, 'lambda_l2': 4.901486126391635e-06}. Best is trial 52 with value: 0.9999546261192224.\u001b[0m\n",
      "regularization_factors, val_score: 1.000000:  75%|#######5  | 15/20 [00:38<00:11,  2.38s/it][100]\tcv_agg's auc: 0.999509 + 0.000695003\n",
      "regularization_factors, val_score: 1.000000:  80%|########  | 16/20 [00:39<00:08,  2.20s/it]\u001b[32m[I 2021-01-22 16:38:08,321]\u001b[0m Trial 58 finished with value: 0.9999643789680173 and parameters: {'lambda_l1': 1.2687382252599456e-05, 'lambda_l2': 7.488007308888824}. Best is trial 58 with value: 0.9999643789680173.\u001b[0m\n",
      "regularization_factors, val_score: 1.000000:  80%|########  | 16/20 [00:40<00:08,  2.20s/it][100]\tcv_agg's auc: 0.999639 + 0.000510787\n",
      "regularization_factors, val_score: 1.000000:  85%|########5 | 17/20 [00:45<00:09,  3.08s/it][100]\tcv_agg's auc: 0.999542 + 0.000648219\n",
      "\u001b[32m[I 2021-01-22 16:38:13,461]\u001b[0m Trial 59 finished with value: 0.9997341853035143 and parameters: {'lambda_l1': 9.568552386394983e-06, 'lambda_l2': 7.976711083642609e-07}. Best is trial 58 with value: 0.9999643789680173.\u001b[0m\n",
      "regularization_factors, val_score: 1.000000:  90%|######### | 18/20 [00:47<00:06,  3.01s/it]\u001b[32m[I 2021-01-22 16:38:16,299]\u001b[0m Trial 60 finished with value: 0.9996092055308812 and parameters: {'lambda_l1': 1.542509369146608e-08, 'lambda_l2': 0.06681567517813614}. Best is trial 58 with value: 0.9999643789680173.\u001b[0m\n",
      "regularization_factors, val_score: 1.000000:  90%|######### | 18/20 [00:48<00:06,  3.01s/it][100]\tcv_agg's auc: 0.999516 + 0.000685164\n",
      "regularization_factors, val_score: 1.000000:  95%|#########5| 19/20 [00:51<00:03,  3.07s/it]\u001b[32m[I 2021-01-22 16:38:19,497]\u001b[0m Trial 61 finished with value: 0.9996407597151068 and parameters: {'lambda_l1': 1.0881695896813096e-05, 'lambda_l2': 0.0020128918249049704}. Best is trial 58 with value: 0.9999643789680173.\u001b[0m\n",
      "regularization_factors, val_score: 1.000000:  95%|#########5| 19/20 [00:51<00:03,  3.07s/it][100]\tcv_agg's auc: 0.999492 + 0.000719113\n",
      "regularization_factors, val_score: 1.000000: 100%|##########| 20/20 [00:54<00:00,  3.30s/it]\u001b[32m[I 2021-01-22 16:38:23,330]\u001b[0m Trial 62 finished with value: 0.999611144924596 and parameters: {'lambda_l1': 1.788002168725181e-05, 'lambda_l2': 0.0007683202060136458}. Best is trial 58 with value: 0.9999643789680173.\u001b[0m\n",
      "regularization_factors, val_score: 1.000000: 100%|##########| 20/20 [00:55<00:00,  2.75s/it]\n",
      "min_data_in_leaf, val_score: 1.000000:   0%|          | 0/5 [00:00<?, ?it/s][100]\tcv_agg's auc: 0.999481 + 0.000734029\n",
      "[100]\tcv_agg's auc: 0.999529 + 0.000665388\n",
      "min_data_in_leaf, val_score: 1.000000:  20%|##        | 1/5 [00:08<00:34,  8.66s/it]\u001b[32m[I 2021-01-22 16:38:32,102]\u001b[0m Trial 63 finished with value: 0.9996823698268321 and parameters: {'min_child_samples': 25}. Best is trial 63 with value: 0.9996823698268321.\u001b[0m\n",
      "min_data_in_leaf, val_score: 1.000000:  20%|##        | 1/5 [00:08<00:34,  8.66s/it][100]\tcv_agg's auc: 0.999633 + 0.000518795\n",
      "min_data_in_leaf, val_score: 1.000000:  40%|####      | 2/5 [00:37<01:01, 20.59s/it]\u001b[32m[I 2021-01-22 16:39:01,030]\u001b[0m Trial 64 finished with value: 0.9996565335059656 and parameters: {'min_child_samples': 5}. Best is trial 63 with value: 0.9996823698268321.\u001b[0m\n",
      "min_data_in_leaf, val_score: 1.000000:  40%|####      | 2/5 [00:37<01:01, 20.59s/it][100]\tcv_agg's auc: 0.999497 + 0.000710644\n",
      "min_data_in_leaf, val_score: 1.000000:  60%|######    | 3/5 [00:56<00:39, 19.80s/it]\u001b[32m[I 2021-01-22 16:39:19,904]\u001b[0m Trial 65 finished with value: 0.9996364153988369 and parameters: {'min_child_samples': 10}. Best is trial 63 with value: 0.9996823698268321.\u001b[0m\n",
      "min_data_in_leaf, val_score: 1.000000:  80%|########  | 4/5 [01:00<00:13, 13.60s/it]\u001b[32m[I 2021-01-22 16:39:24,000]\u001b[0m Trial 66 finished with value: 0.9997824566855722 and parameters: {'min_child_samples': 50}. Best is trial 66 with value: 0.9997824566855722.\u001b[0m\n",
      "min_data_in_leaf, val_score: 1.000000:  80%|########  | 4/5 [01:00<00:13, 13.60s/it][100]\tcv_agg's auc: 0.99962 + 0.000537171\n",
      "min_data_in_leaf, val_score: 1.000000: 100%|##########| 5/5 [01:02<00:00,  9.55s/it]\u001b[32m[I 2021-01-22 16:39:26,376]\u001b[0m Trial 67 finished with value: 0.9996312146833827 and parameters: {'min_child_samples': 100}. Best is trial 66 with value: 0.9997824566855722.\u001b[0m\n",
      "min_data_in_leaf, val_score: 1.000000: 100%|##########| 5/5 [01:03<00:00, 12.61s/it][100]\tcv_agg's auc: 0.999549 + 0.000638121\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<lightgbm.basic.Booster at 0x7fd4140d2430>,\n",
       " <lightgbm.basic.Booster at 0x7fd4140d2880>,\n",
       " <lightgbm.basic.Booster at 0x7fd4140c9520>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_data = lgb.Dataset(x, label=y)\n",
    "\n",
    "param = {\n",
    "    'device_type': 'gpu',\n",
    "    'objective': 'binary',\n",
    "    'boosting': 'gbdt',\n",
    "    \"verbosity\": -1,\n",
    "    # 'metric': 'kullback_leibler',\n",
    "    'metric': 'auc',\n",
    "    # 'is_unbalance': True,\n",
    "}\n",
    "tuner = optuna_lgb.LightGBMTunerCV(param,\n",
    "                                   train_data,\n",
    "                                   stratified=False,\n",
    "                                   verbose_eval=100,\n",
    "                                   early_stopping_rounds=100,\n",
    "                                   return_cvbooster=True,\n",
    "                                   folds=KFold(n_splits=3, shuffle=True))\n",
    "tuner.run()\n",
    "bst = tuner.get_best_booster()\n",
    "bst.save_model('model.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0, 0.0, 0.0, 0.0, 0.0, 6, 22, 8, 1.0799589994281866], [0.0, 0.0, 0.0, 0.0, 0.0, 6, 5, 1, 2.718281828459045], [0.0, 0.0, 0.0, 0.0, 0.0, 6, 4, 4, 1.2840254166877414], [0.0, 0.0, 0.0, 0.0, 0.0, 6, 4, 4, 1.2840254166877414], [0.0, 0.0, 0.0, 0.0, 0.0, 6, 3, 3, 1.3956124250860895], [0.0, 0.0, 0.0, 0.0, 0.0, 6, 1, 1, 2.718281828459045], [0.0, 0.0, 0.0, 0.0, 0.0, 6, 7, 6, 1.1535649948951077], [0.0, 0.0, 0.0, 0.0, 0.0, 6, 6, 2, 1.1813604128656459], [0.0, 0.0, 0.0, 0.0, 0.0, 6, 24, 2, 1.0425469051899914], [0.0, 0.0, 0.0, 0.0, 0.0, 6, 59, 1, 2.718281828459045], [0.0, 0.0, 0.0, 0.0, 0.0, 6, 6, 2, 1.1813604128656459], [0.0, 0.0, 0.0, 0.0, 0.0, 6, 42, 9, 1.0281671774377144]]\n",
      "[array([0.99992939, 0.9997595 , 0.99984053, 0.9997621 , 0.99937809,\n",
      "       0.99983484, 0.99958312, 0.99974632, 0.99988421, 0.99994937,\n",
      "       0.99942193, 0.99993532]), array([0.9999371 , 0.99958398, 0.99990516, 0.99970879, 0.99888799,\n",
      "       0.99965583, 0.99935672, 0.99965481, 0.99961416, 0.99996899,\n",
      "       0.9994327 , 0.99988839]), array([0.99990964, 0.99974634, 0.99977099, 0.99977602, 0.99967543,\n",
      "       0.99986807, 0.99964842, 0.99989456, 0.99995533, 0.99991018,\n",
      "       0.99964756, 0.99996357])]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'list' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/repos/src/github.com/uetchy/vespa/trainer/train.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mval_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_pred\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.65\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'list' and 'float'"
     ]
    }
   ],
   "source": [
    "msg = [\n",
    "    'HEEERRREESSS SUISEI~~~', 'wwwww', 'なにそれ', 'YABE', 'やばい', '草', 'lol why',\n",
    "    'クソクソクソ', '死ね死ね死ね死ね死ね死ね死ね死ね死ね死ね死ね死ね',\n",
    "    'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa', 'きもきもきも',\n",
    "    'パピオン加藤最強!!パピオン加藤最強!!!パピオン加藤最強!!パピオン加藤最強!!!'\n",
    "]\n",
    "bwt = np.nan\n",
    "test_data = [[\n",
    "    0.0, 0.0, 0.0, 0.0, 0.0, 6,\n",
    "    len(x),\n",
    "    len(set(x)),\n",
    "    balanced_bwt_rl_entropy([x])\n",
    "] for x in msg]\n",
    "print(test_data)\n",
    "test_df = pd.DataFrame(test_data,\n",
    "                       columns=[\n",
    "                           'isVerified', 'isOwner', 'isModerator', 'isMember',\n",
    "                           'isSuperchat', 'authorLength', 'messageLength',\n",
    "                           'messageUniqueness', 'bwtrl'\n",
    "                       ])\n",
    "embeds = model.encode(msg)\n",
    "emb_columns = ['emb_' + str(i) for i in range(embeds.shape[1])]\n",
    "test_df[emb_columns] = embeds\n",
    "test_df['isMember'] = test_df['isMember']\n",
    "test_df['isSuperchat'] = test_df['isSuperchat']\n",
    "sam = data[data['spam'] == 1.0].sample(10)\n",
    "val_pred = bst.predict(test_df)\n",
    "print(val_pred)\n",
    "print((val_pred > 0.65).astype(int))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
