{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "import zlib\n",
    "import itertools\n",
    "import re\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "data_dir = '../../data/'\n",
    "raw_data_dir = join(data_dir, 'raw')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def suffix_array(arr):\n",
    "    arr_size = len(arr)\n",
    "    arr_int = {v: k for k, v in enumerate(sorted(set(arr)))}\n",
    "    arr = [arr_int[x] for x in arr]\n",
    "    arr.append(-1)\n",
    "    suf = [[i, arr[i], arr[i + 1]] for i in range(arr_size)]\n",
    "    suf.sort(key=itemgetter(1, 2))\n",
    "    idx = [0] * arr_size\n",
    "    k = 2\n",
    "    while k < arr_size:\n",
    "        r = 0\n",
    "        prev_r = suf[0][1]\n",
    "        for i in range(arr_size):\n",
    "            if suf[i][1] != prev_r or suf[i - 1][2] != suf[i][2]:\n",
    "                r += 1\n",
    "            prev_r = suf[i][1]\n",
    "            suf[i][1] = r\n",
    "            idx[suf[i][0]] = i\n",
    "        for i in range(arr_size):\n",
    "            next_idx = suf[i][0] + k\n",
    "            suf[i][2] = suf[idx[next_idx]][1] if next_idx < arr_size else -1\n",
    "        suf.sort(key=itemgetter(1, 2))\n",
    "        k <<= 1\n",
    "    return [x[0] for x in suf]\n",
    "\n",
    "def bwt_encode(data):\n",
    "    data_ref = suffix_array(data)\n",
    "    bwt_ref = (x - 1 for x in data_ref)\n",
    "    return ''.join([source[x] for x in bwt_ref])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# of files: 24\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1852551 entries, 0 to 11099\n",
      "Data columns (total 17 columns):\n",
      " #   Column           Dtype         \n",
      "---  ------           -----         \n",
      " 0   type             object        \n",
      " 1   id               object        \n",
      " 2   timestampUsec    datetime64[ns]\n",
      " 3   rawMessage       object        \n",
      " 4   authorName       object        \n",
      " 5   authorChannelId  object        \n",
      " 6   authorPhoto      object        \n",
      " 7   isVerified       float64       \n",
      " 8   isOwner          float64       \n",
      " 9   isModerator      float64       \n",
      " 10  message          object        \n",
      " 11  membership       object        \n",
      " 12  originVideoId    object        \n",
      " 13  originChannelId  object        \n",
      " 14  targetId         object        \n",
      " 15  purchase         object        \n",
      " 16  channelId        object        \n",
      "dtypes: datetime64[ns](1), float64(3), object(13)\n",
      "memory usage: 254.4+ MB\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob(join(raw_data_dir, \"*.jsonl\"))\n",
    "print(f'# of files: {str(len(files))}')\n",
    "files = [pd.read_json(open(f), lines=True) for f in files]\n",
    "\n",
    "# concat df\n",
    "df = pd.concat(files, axis=0)\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform\n",
    "chat_df = df[df[\"type\"] == \"addChatItemAction\"]\n",
    "chat_df.drop(columns=[\n",
    "    'type',\n",
    "    'channelId',\n",
    "    'targetId',\n",
    "], inplace=True)\n",
    "chat_df.drop_duplicates('id', inplace=True)\n",
    "\n",
    "# remove old chat which has no origin info\n",
    "chat_df.dropna(subset=['originVideoId'], inplace=True)\n",
    "\n",
    "# sort by time\n",
    "chat_df.sort_values(by=['timestampUsec'], inplace=True)\n",
    "\n",
    "ban_df = df[df[\"type\"] == \"markChatItemsByAuthorAsDeletedAction\"]\n",
    "ban_df = ban_df[['channelId', 'originVideoId', 'originChannelId']]\n",
    "ban_df.rename(columns={'channelId': 'authorChannelId'}, inplace=True)\n",
    "ban_df.dropna(subset=['originVideoId'], inplace=True)\n",
    "ban_df.drop_duplicates(inplace=True)\n",
    "\n",
    "delete_actions_df = df[df[\"type\"] == \"markChatItemAsDeletedAction\"]\n",
    "delete_actions_df = delete_actions_df[[\n",
    "    'targetId', 'originVideoId', 'originChannelId'\n",
    "]]\n",
    "\n",
    "# remove custom emojis\n",
    "chat_df['message'] = chat_df['message'].replace(to_replace ='<.+?>', value = '', regex = True)\n",
    "\n",
    "# remove chat with empty message\n",
    "chat_df = chat_df[chat_df['message'].astype(bool)]\n",
    "\n",
    "spam_excludes = pd.read_csv(join(data_dir, 'spam_exclusion.txt'),\n",
    "                            header=None,\n",
    "                            squeeze=True)\n",
    "\n",
    "# # assume chat with flagged as deletion as spam\n",
    "# chat_df['spam'] = chat_df['authorChannelId'].isin(spam_ids)\n",
    "\n",
    "ban_df['marked'] = True\n",
    "markedChatByModerators = pd.merge(chat_df, ban_df, on=['authorChannelId', 'originVideoId', 'originChannelId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1314386 entries, 237237 to 11099\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count    Dtype         \n",
      "---  ------           --------------    -----         \n",
      " 0   id               1314386 non-null  object        \n",
      " 1   timestampUsec    1314386 non-null  datetime64[ns]\n",
      " 2   rawMessage       1313772 non-null  object        \n",
      " 3   authorName       1314181 non-null  object        \n",
      " 4   authorChannelId  1314386 non-null  object        \n",
      " 5   authorPhoto      1314386 non-null  object        \n",
      " 6   isVerified       1314386 non-null  float64       \n",
      " 7   isOwner          1314386 non-null  float64       \n",
      " 8   isModerator      1314386 non-null  float64       \n",
      " 9   message          1313772 non-null  object        \n",
      " 10  membership       551260 non-null   object        \n",
      " 11  originVideoId    1314386 non-null  object        \n",
      " 12  originChannelId  1314386 non-null  object        \n",
      " 13  purchase         6872 non-null     object        \n",
      "dtypes: datetime64[ns](1), float64(3), object(10)\n",
      "memory usage: 150.4+ MB\n",
      "None\n",
      "8018\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1314386 entries, 0 to 1314385\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count    Dtype         \n",
      "---  ------           --------------    -----         \n",
      " 0   id               1314386 non-null  object        \n",
      " 1   timestampUsec    1314386 non-null  datetime64[ns]\n",
      " 2   rawMessage       1313772 non-null  object        \n",
      " 3   authorName       1314181 non-null  object        \n",
      " 4   authorChannelId  1314386 non-null  object        \n",
      " 5   authorPhoto      1314386 non-null  object        \n",
      " 6   isVerified       1314386 non-null  float64       \n",
      " 7   isOwner          1314386 non-null  float64       \n",
      " 8   isModerator      1314386 non-null  float64       \n",
      " 9   message          1313772 non-null  object        \n",
      " 10  membership       551260 non-null   object        \n",
      " 11  originVideoId    1314386 non-null  object        \n",
      " 12  originChannelId  1314386 non-null  object        \n",
      " 13  purchase         6872 non-null     object        \n",
      " 14  marked           8018 non-null     object        \n",
      "dtypes: datetime64[ns](1), float64(3), object(11)\n",
      "memory usage: 160.4+ MB\n"
     ]
    }
   ],
   "source": [
    "print(chat_df.info())\n",
    "print(len(pd.merge(chat_df, ban_df, on=['authorChannelId', 'originVideoId', 'originChannelId'])))\n",
    "markedChatByModerators = pd.merge(chat_df, ban_df, on=['authorChannelId', 'originVideoId', 'originChannelId'], how='left')\n",
    "markedChatByModerators.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                        id  \\\n",
       "1319149  CjkKGkNOemtuXzJTci00Q0ZjZzNyUVlkMkhnTVBREhtDTk...   \n",
       "1319150  CjkKGkNQajQwUDJTci00Q0Zid1RyUVlkeF93RFZREhtDTm...   \n",
       "1319151  CkUKGkNJYV9oZi1Tci00Q0ZVS1B3Z0VkWG04RDNBEidDTm...   \n",
       "1319152  CjkKGkNQQ0l2Zi1Tci00Q0ZiZ1VyUVlkSS00S1lBEhtDT1...   \n",
       "1319153  CjoKGkNJckt2Zi1Tci00Q0Zjd0RyUVlkdl93RzRREhxDTz...   \n",
       "\n",
       "                     timestampUsec  \\\n",
       "1319149 2021-01-22 08:43:45.270415   \n",
       "1319150 2021-01-22 08:43:46.075821   \n",
       "1319151 2021-01-22 08:43:49.033902   \n",
       "1319152 2021-01-22 08:43:49.944465   \n",
       "1319153 2021-01-22 08:43:49.952804   \n",
       "\n",
       "                                              rawMessage        authorName  \\\n",
       "1319149                  {'runs': [{'text': 'まだー３８痛い'}]}              くろの。   \n",
       "1319150                {'runs': [{'text': 'BIG BRAIN'}]}     Yisrine Yuuki   \n",
       "1319151        {'runs': [{'text': 'you got this Aqua'}]}  Celestial Archon   \n",
       "1319152  {'runs': [{'text': 'Sololive oniooon clutch'}]}         Jslz cbbd   \n",
       "1319153       {'runs': [{'text': '速攻促進剤つかっても無理っぽかったな'}]}           STINGER   \n",
       "\n",
       "                  authorChannelId  \\\n",
       "1319149  UChdPR-yQm3nfyyC2Y2JGlCw   \n",
       "1319150  UCVuaf43_WWvhLyb6fwpUclw   \n",
       "1319151  UCMaTPWrw8p_Hm43l2IzcYTQ   \n",
       "1319152  UChoODK7uJraJSpUjaBN0_zQ   \n",
       "1319153  UCMBqEKxkpI3htzdTckodWdw   \n",
       "\n",
       "                                               authorPhoto  isVerified  \\\n",
       "1319149  https://yt4.ggpht.com/ytc/AAUvwnh6riGnaM85bnqh...         0.0   \n",
       "1319150  https://yt4.ggpht.com/ytc/AAUvwnhzSFy0fA5y9VGb...         0.0   \n",
       "1319151  https://yt4.ggpht.com/ytc/AAUvwngxxISK6xwI-GNG...         0.0   \n",
       "1319152  https://yt4.ggpht.com/ytc/AAUvwnggslWMjvBC7d2-...         0.0   \n",
       "1319153  https://yt4.ggpht.com/ytc/AAUvwnjXNaiw3ZUCPYLu...         0.0   \n",
       "\n",
       "         isOwner  isModerator                  message membership  \\\n",
       "1319149      0.0          0.0                  まだー３８痛い        NaN   \n",
       "1319150      0.0          0.0                BIG BRAIN        NaN   \n",
       "1319151      0.0          0.0        you got this Aqua        NaN   \n",
       "1319152      0.0          0.0  Sololive oniooon clutch        NaN   \n",
       "1319153      0.0          0.0       速攻促進剤つかっても無理っぽかったな        NaN   \n",
       "\n",
       "        originVideoId           originChannelId purchase marked  \n",
       "1319149   x2k0FCEHNqM  UC1opHUrw8rvnsadT-iGp7Cg      NaN    NaN  \n",
       "1319150   x2k0FCEHNqM  UC1opHUrw8rvnsadT-iGp7Cg      NaN    NaN  \n",
       "1319151   x2k0FCEHNqM  UC1opHUrw8rvnsadT-iGp7Cg      NaN    NaN  \n",
       "1319152   x2k0FCEHNqM  UC1opHUrw8rvnsadT-iGp7Cg      NaN    NaN  \n",
       "1319153   x2k0FCEHNqM  UC1opHUrw8rvnsadT-iGp7Cg      NaN    NaN  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>timestampUsec</th>\n      <th>rawMessage</th>\n      <th>authorName</th>\n      <th>authorChannelId</th>\n      <th>authorPhoto</th>\n      <th>isVerified</th>\n      <th>isOwner</th>\n      <th>isModerator</th>\n      <th>message</th>\n      <th>membership</th>\n      <th>originVideoId</th>\n      <th>originChannelId</th>\n      <th>purchase</th>\n      <th>marked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1319149</th>\n      <td>CjkKGkNOemtuXzJTci00Q0ZjZzNyUVlkMkhnTVBREhtDTk...</td>\n      <td>2021-01-22 08:43:45.270415</td>\n      <td>{'runs': [{'text': 'まだー３８痛い'}]}</td>\n      <td>くろの。</td>\n      <td>UChdPR-yQm3nfyyC2Y2JGlCw</td>\n      <td>https://yt4.ggpht.com/ytc/AAUvwnh6riGnaM85bnqh...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>まだー３８痛い</td>\n      <td>NaN</td>\n      <td>x2k0FCEHNqM</td>\n      <td>UC1opHUrw8rvnsadT-iGp7Cg</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1319150</th>\n      <td>CjkKGkNQajQwUDJTci00Q0Zid1RyUVlkeF93RFZREhtDTm...</td>\n      <td>2021-01-22 08:43:46.075821</td>\n      <td>{'runs': [{'text': 'BIG BRAIN'}]}</td>\n      <td>Yisrine Yuuki</td>\n      <td>UCVuaf43_WWvhLyb6fwpUclw</td>\n      <td>https://yt4.ggpht.com/ytc/AAUvwnhzSFy0fA5y9VGb...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>BIG BRAIN</td>\n      <td>NaN</td>\n      <td>x2k0FCEHNqM</td>\n      <td>UC1opHUrw8rvnsadT-iGp7Cg</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1319151</th>\n      <td>CkUKGkNJYV9oZi1Tci00Q0ZVS1B3Z0VkWG04RDNBEidDTm...</td>\n      <td>2021-01-22 08:43:49.033902</td>\n      <td>{'runs': [{'text': 'you got this Aqua'}]}</td>\n      <td>Celestial Archon</td>\n      <td>UCMaTPWrw8p_Hm43l2IzcYTQ</td>\n      <td>https://yt4.ggpht.com/ytc/AAUvwngxxISK6xwI-GNG...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>you got this Aqua</td>\n      <td>NaN</td>\n      <td>x2k0FCEHNqM</td>\n      <td>UC1opHUrw8rvnsadT-iGp7Cg</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1319152</th>\n      <td>CjkKGkNQQ0l2Zi1Tci00Q0ZiZ1VyUVlkSS00S1lBEhtDT1...</td>\n      <td>2021-01-22 08:43:49.944465</td>\n      <td>{'runs': [{'text': 'Sololive oniooon clutch'}]}</td>\n      <td>Jslz cbbd</td>\n      <td>UChoODK7uJraJSpUjaBN0_zQ</td>\n      <td>https://yt4.ggpht.com/ytc/AAUvwnggslWMjvBC7d2-...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Sololive oniooon clutch</td>\n      <td>NaN</td>\n      <td>x2k0FCEHNqM</td>\n      <td>UC1opHUrw8rvnsadT-iGp7Cg</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1319153</th>\n      <td>CjoKGkNJckt2Zi1Tci00Q0Zjd0RyUVlkdl93RzRREhxDTz...</td>\n      <td>2021-01-22 08:43:49.952804</td>\n      <td>{'runs': [{'text': '速攻促進剤つかっても無理っぽかったな'}]}</td>\n      <td>STINGER</td>\n      <td>UCMBqEKxkpI3htzdTckodWdw</td>\n      <td>https://yt4.ggpht.com/ytc/AAUvwnjXNaiw3ZUCPYLu...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>速攻促進剤つかっても無理っぽかったな</td>\n      <td>NaN</td>\n      <td>x2k0FCEHNqM</td>\n      <td>UC1opHUrw8rvnsadT-iGp7Cg</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "markedChatByModerators.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_rows = chat_df['authorChannelId'].isin(spam_ids)\n",
    "chat_df.loc[spam_rows, 'message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spam_df = chat_df[chat_df['spam']==1.0].reset_index(drop=True)\n",
    "# print(spam_df.head())\n",
    "spam_df['timestampUsec'] = pd.to_datetime(spam_df['timestampUsec'], unit='us')\n",
    "def calc_bwtrl(df):\n",
    "    hist = spam_df[(spam_df['authorChannelId'] == df['authorChannelId']) & (spam_df['originVideoId'] == df['originVideoId']) & (spam_df['timestampUsec'] <= df['timestampUsec'])][:100]\n",
    "    return accum_entropy(hist['message'].to_list())\n",
    "s = spam_df\n",
    "s['bwtrl'] = s.progress_apply(lambda x: calc_bwtrl(x), axis=1)\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "pd.options.display.max_rows = 500\n",
    "high = s[s['bwtrl'] > 50]\n",
    "high.sort_values(by=['bwtrl','authorName'])[['bwtrl','message','authorName','authorChannelId']]\n",
    "# pd.Series(high['authorChannelId'].unique()).to_csv('highly_spam.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# preprocessing\n",
    "\n",
    "# delete redundant chat\n",
    "deletedChatIds = delete_actions_df['targetId']\n",
    "chat_df.drop(chat_df[chat_df['id'].isin(deletedChatIds)].index,\n",
    "                inplace=True)\n",
    "\n",
    "# remove chat with empty message (mostly superchat?)\n",
    "# for later processing in sentence encoding\n",
    "chat_df = chat_df[chat_df['message'].notnull()]\n",
    "\n",
    "# boolean features\n",
    "chat_df['isMember'] = pd.notna(chat_df['membership'])\n",
    "chat_df['isSuperchat'] = chat_df['purchase'].notna()\n",
    "chat_df['isOwner'].fillna(False)\n",
    "chat_df['isVerified'].fillna(False)\n",
    "chat_df['isModerator'].fillna(False)\n",
    "\n",
    "# manually exclude wrongly flagged users\n",
    "spam_ids = ban_df[\"channelId\"]\n",
    "spam_excludes = pd.read_csv(join(data_dir, 'spam_exclusion.txt'),\n",
    "                            header=None,\n",
    "                            squeeze=True)\n",
    "spam_ids = spam_ids[~spam_ids.isin(spam_excludes)]\n",
    "\n",
    "# assume chat with flagged as deletion as spam\n",
    "chat_df['spam'] = chat_df['authorChannelId'].isin(spam_ids).astype(\n",
    "    'float64')\n",
    "\n",
    "# count features\n",
    "chat_df['authorLength'] = chat_df['authorName'].apply(lambda x: len(str(x)))\n",
    "chat_df['messageLength'] = chat_df['message'].apply(lambda x: len(str(x)))\n",
    "chat_df['messageUniqueness'] = chat_df['message'].apply(\n",
    "    lambda x: len(set(str(x))))\n",
    "\n",
    "def calc_bwtrl(df):\n",
    "    hist = chat_df[chat_df['authorChannelId'] == df['authorChannelId']]['message']\n",
    "    print(hist)\n",
    "\n",
    "# bwt rl entropy\n",
    "chat_df['bwtRlEntropy'] = chat_df['message'].apply(\n",
    "    lambda x: len(set(str(x))))\n",
    "\n",
    "# encode message to embedding vector\n",
    "# model = SentenceTransformer('paraphrase-xlm-r-multilingual-v1')\n",
    "# message_array = chat_df['message'].to_list()\n",
    "# embeds = model.encode(message_array, show_progress_bar=True)\n",
    "# emb_columns = ['emb_' + str(i) for i in range(embeds.shape[1])]\n",
    "# edf = pd.DataFrame(embeds, columns=emb_columns)\n",
    "# chat_df[emb_columns] = edf\n",
    "\n",
    "chat_df['isMember'] = chat_df['isMember'].astype('category')\n",
    "chat_df['isSuperchat'] = chat_df['isSuperchat'].astype('category')\n",
    "chat_df['isOwner'] = chat_df['isOwner'].astype('category')\n",
    "chat_df['isVerified'] = chat_df['isVerified'].astype('category')\n",
    "chat_df['isModerator'] = chat_df['isModerator'].astype('category')\n",
    "\n",
    "chat_df.drop(columns=[\n",
    "    'id', 'type', 'authorName', 'authorPhoto', 'authorChannelId',\n",
    "    'membership', 'purchase', 'rawMessage', 'timestampUsec', 'channelId',\n",
    "    'targetId', 'originChannelId', 'originVideoId', 'message'\n",
    "],\n",
    "                inplace=True)\n",
    "\n",
    "# review\n",
    "chat_df.info()\n",
    "print(chat_df.head())\n",
    "\n",
    "print(f\"# of chat: {str(len(chat_df))}\")\n",
    "print(f\"# of banActions: {str(len(ban_df))}\")\n",
    "print(f\"# of deleteActions: {str(len(delete_actions_df))}\")\n",
    "\n",
    "markedAsSpam = chat_df[chat_df[\"spam\"] == 1.0]\n",
    "harmless = chat_df[chat_df[\"spam\"] == 0.0]\n",
    "print(f'# of spam: {str(len(markedAsSpam))}')\n",
    "print(markedAsSpam.describe())\n",
    "print(f'# of not spam: {str(len(harmless))}')\n",
    "print(harmless.describe())\n",
    "print(\"spam ratio: \", len(markedAsSpam) / len(harmless))\n",
    "\n",
    "# split data frame\n",
    "\n",
    "# markedAsSpam = markedAsSpam.sort_values('authorName')\n",
    "# target_col = [\"authorName\", \"authorChannelId\", \"message\"]\n",
    "# markedAsSpam[target_col].to_csv(join(data_dir, 'spam.csv'))\n",
    "\n",
    "# create dataset\n",
    "\n",
    "chat_df.to_parquet(join(data_dir, 'train.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}